{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(X_train,Y_train) , (X_test,Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train , X_test = X_train/255. , X_test/255."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "shape=(50,50)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "Path = ['D:/Data/MultiDomain/Dataset/Animals/cats/','D:/Data/MultiDomain/Dataset/Animals/dogs/']#,'D:/Data/MultiDomain/Dataset/Animals/fox/']\n",
    "for i in Path :\n",
    "    co = 0\n",
    "    for j in os.listdir(i) :\n",
    "        img = cv2.imread(i+j)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img,(shape[:2]))\n",
    "        co += 1\n",
    "        if co >= 100 and co <= 125 :\n",
    "            X_test.append(img)\n",
    "            Y_test.append(Path.index(i))\n",
    "        elif co < 100 :\n",
    "            X_train.append(img)\n",
    "            Y_train.append(Path.index(i))\n",
    "        else :\n",
    "            break\n",
    "X_train = np.array(X_train)/255.\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)/255.\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (30km/h)', 'Speed limit (60km/h)']\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "size = 100\n",
    "#ReqLabels = [1,3,5,7,14]#,17,19,20,26,33,34,36,37,38,39]\n",
    "#ReqLabels = [1,3,5,7,14,17,19,20,26,33,34,36,37,38,39]\n",
    "ReqLabels = [1,3]\n",
    "\n",
    "Train_Path = 'D:/Data/Traffic Signs/Train.csv'\n",
    "Test_Path = 'D:/Data/Traffic Signs/Test.csv'\n",
    "Meta_Path = 'D:/Data/Traffic Signs/Meta.csv'\n",
    "Labels_Path = 'D:/Data/Traffic Signs/Labels.csv'\n",
    "\n",
    "Labels = []\n",
    "labelData = pd.read_csv(Labels_Path)\n",
    "for i,j in zip(labelData['ClassId'] , labelData['SignName']) :\n",
    "    if i in ReqLabels :\n",
    "        Labels.append(j)\n",
    "        \n",
    "print(Labels)\n",
    "\n",
    "### 30 , 50 , 70 , 100 km/h and No entry , Stop , 19,20,27,33,34,35,36,37,38,39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(Meta_Path)\n",
    "NoOfLabels = len(data['Path'])\n",
    "print(NoOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 3: 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(Dir,typeLoad,count=100) :\n",
    "    data = pd.read_csv(Dir)\n",
    "    display(data.head())\n",
    "    X , Y = [] , []\n",
    "    for i,rx1,ry1,rx2,ry2,cId in zip(data['Path'],data['Roi.X1'],data['Roi.Y1'],data['Roi.X2'],data['Roi.Y2'],data['ClassId']) :\n",
    "        if cId in ReqLabels :\n",
    "            print(f'\\r{len(X)}\\t\\t',end=\"\")\n",
    "            i = 'D:/Data/Traffic Signs/' + i\n",
    "            img = cv2.imread(i)\n",
    "            #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            img = img[ry1:ry2,rx1:rx2]\n",
    "            img = cv2.resize(img,(size,size))\n",
    "            if Count_Labels[cId] <= count-1 :\n",
    "                X.append(img)\n",
    "                Y.append(ReqLabels.index(cId))\n",
    "                if typeLoad == 'Train' or typeLoad == 'Test' :\n",
    "                    Count_Labels[cId] += 1\n",
    "        \n",
    "    return np.array(X)/255. , np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\t\t"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = LoadData(Train_Path,'Train',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 100, 3: 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 3: 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\t\t"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = LoadData(Test_Path,'Test',25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 25, 3: 25}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (200, 100, 100, 3), Y_train shape : (200,)\n",
      "X_test shape : (50, 100, 100, 3), Y_test shape : (50,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code Train and Test data pickle dumping and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Model_Check.obj'\n",
    "def callback(obj,fileName) :\n",
    "    print('CallBack : ',fileName,'Updated')\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N_F = No of Neurons\n",
    "* A_F = Activation Function\n",
    "* __Name__ = class of the name\n",
    "* __type__ = type of the class what it's do\n",
    "* K_S = Kernel size\n",
    "* STRIDES = how many pixels it moves at a time\n",
    "* pad = no of 0's border to add\n",
    "* input_shape = class input shape to train model\n",
    "* output_shape = output shape of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'ReLU'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.input_shape=X.shape\n",
    "        self.output = np.maximum(0,X)\n",
    "        self.output_shape = self.input_shape\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        grad = Z > 0\n",
    "        #print(grad.shape,grad_output.shape)\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Softmax :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Softmax'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        e_x = np.exp(X-np.max(X))\n",
    "        self.output = e_x/e_x.sum()\n",
    "        return np.exp(X)/np.sum(np.exp(X))\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        e_x = np.exp(X)\n",
    "        return (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        e_x = np.exp(Z)\n",
    "        out = e_x/ex.sum()\n",
    "        grad = (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "        #grad = e_x/e_x.sum()**2 - (e_x**2/(e_x.sum()**2))\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Sigmoid :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Sigmoid'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.output = 1/(1+np.exp(-X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        out = 1/(1+np.exp(-X))\n",
    "        return out*(1-out)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        out = 1/(1+np.exp(-Z))\n",
    "        grad = out*((1-out)**2)\n",
    "        return grad_output*grad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "w2 = (w1-f+2P)/s + 1\n",
    "W1 — is the width / height of the input tensor\n",
    "F — is the width / height of the kernel\n",
    "P — is the padding\n",
    "S — is the stride\n",
    "W2 — is the output width / height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Convolution` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Conv2D :\n",
    "    \n",
    "    def __init__ (self,N_F,K_S,A_F,input_shape,STRIDES=1,pad=0) :\n",
    "        self.__Name__ = 'Conv2D'\n",
    "        self.__type__ = 'conv'\n",
    "        self.N_F = N_F\n",
    "        self.K_S = K_S\n",
    "        self.STRIDES = STRIDES\n",
    "        self.A_F = A_F\n",
    "        self.pad = pad\n",
    "        if (len(input_shape) == 2) :\n",
    "            self.input_shape = input_shape+(1,)\n",
    "        else :\n",
    "            self.input_shape = input_shape\n",
    "        self.Filters = np.random.normal(size=(self.N_F,self.input_shape[-1],self.K_S,self.K_S))\n",
    "        self.W = int((self.input_shape[0]-self.K_S+2*self.pad)/self.STRIDES) + 1\n",
    "        self.H = int((self.input_shape[1]-self.K_S+2*self.pad)/self.STRIDES) + 1\n",
    "        self.D = self.N_F\n",
    "        self.bias = np.random.randint(-1,2,(self.N_F))\n",
    "        self.output_shape = (self.W,self.H,self.D)\n",
    "\n",
    "    def feed(self,X) :\n",
    "        output = np.zeros((self.W,self.H,self.D))\n",
    "        for i in range(0,self.W,self.STRIDES) :\n",
    "            for j in range(0,self.H,self.STRIDES) :\n",
    "                cur_reg = X[i:i+self.K_S,j:j+self.K_S].T*self.Filters\n",
    "                output[i,j] = np.sum(cur_reg,axis=(1,2,3)) + self.bias\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def feed_back(self,X) :\n",
    "        return None\n",
    "\n",
    "    def plotImg(self,X=None) :\n",
    "        if X is None :\n",
    "            X = self.output\n",
    "        Filter_SIZE = int(X.shape[-1]**(1/2))\n",
    "        _, axs = plt.subplots(Filter_SIZE,Filter_SIZE, figsize=(8,8))\n",
    "        axs = axs.flatten()\n",
    "        for i , ax in enumerate(axs) :\n",
    "            img = X[:,:,i]\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)\n",
    "    \n",
    "# conv = Conv2D(16,3,'ReLU',input_shape=X_train[0].shape)\n",
    "# conv.Summary()\n",
    "# output = conv.feed(X_train[0])\n",
    "# conv.plotImg(output)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conv = Conv2D(16,3,'ReLU',input_shape=(size,size))\n",
    "img = cv2.imread('D:/Data/TestData/0.png')\n",
    "img = cv2.resize(img,(size,size))\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "output = conv.feed(img)\n",
    "conv.plotImg(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MaxPooling` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MaxPool2D :\n",
    "    \n",
    "    def __init__ (self,K_S,input_shape,STRIDES=2,pad=0) :\n",
    "        self.__Name__ = 'MaxPool2D'\n",
    "        self.__type__ = 'pool'\n",
    "        self.K_S = K_S\n",
    "        self.STRIDES = STRIDES\n",
    "        self.A_F = None\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = (int((self.input_shape[0]-self.K_S+1)/self.STRIDES),int((self.input_shape[0]-self.K_S+1)/self.STRIDES),self.input_shape[-1])\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        W,H,D = self.output_shape\n",
    "        self.output = np.zeros((W,H,D))\n",
    "        w , h = 0 , 0\n",
    "        for i in range(0,self.input_shape[0]-self.K_S,self.STRIDES) :\n",
    "            for j in range(0,self.input_shape[1]-self.K_S,self.STRIDES) :\n",
    "                #print(X[i:i+self.K_S,j:j+self.K_S])\n",
    "                self.output[w,h] = np.max(np.max(X[i:i+self.K_S,j:j+self.K_S].T,axis=1),axis=1)\n",
    "                # (98,10) , (100,12)\n",
    "                h += 1\n",
    "            h = 0\n",
    "            w += 1\n",
    "            \n",
    "        return self.output\n",
    "    \n",
    "    def plotImg(self,X=None) :\n",
    "        if X is None :\n",
    "            X = self.output\n",
    "        Filter_SIZE = int(X.shape[-1]**(1/2))\n",
    "        _, axs = plt.subplots(Filter_SIZE,Filter_SIZE, figsize=(8,8))\n",
    "        axs = axs.flatten()\n",
    "        for i , ax in enumerate(axs) :\n",
    "            img = X[:,:,i]\n",
    "            ax.axis('off')\n",
    "            ax.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)\n",
    "        \n",
    "# maxpool = MaxPool2D(3,input_shape=conv.output_shape)\n",
    "# maxpool.Summary()\n",
    "# output = maxpool.feed(conv.output)\n",
    "# maxpool.plotImg(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Average Pooling` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AvgPool2D :\n",
    "    \n",
    "    def __init__ (self,K_S,input_shape,STRIDES=2) :\n",
    "        self.__Name__ = 'AvgPool2D'\n",
    "        self.__type__ = 'pool'\n",
    "        self.K_S = K_S\n",
    "        self.STRIDES = STRIDES\n",
    "        self.A_F = None\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = (int((self.input_shape[0]-self.K_S+1)/self.STRIDES),int((self.input_shape[0]-self.K_S+1)/self.STRIDES),self.input_shape[-1])\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        W,H,D = self.output_shape\n",
    "        self.output = np.zeros((W,H,D))\n",
    "        w , h = 0 , 0\n",
    "        for i in range(0,self.input_shape[0]-self.K_S,self.STRIDES) :\n",
    "            for j in range(0,self.input_shape[1]-self.K_S,self.STRIDES) :\n",
    "                self.output[w,h] = np.average(np.average(X[i:i+self.K_S,j:j+self.K_S].T,axis=1),axis=1)\n",
    "                h += 1\n",
    "            h = 0\n",
    "            w += 1\n",
    "            \n",
    "        return self.output\n",
    "    \n",
    "    def plotImg(self,X=None) :\n",
    "        if X is None :\n",
    "            X = self.output\n",
    "        Filter_SIZE = int(X.shape[-1]**(1/2))\n",
    "        _, axs = plt.subplots(Filter_SIZE,Filter_SIZE, figsize=(8,8))\n",
    "        axs = axs.flatten()\n",
    "        for i , ax in enumerate(axs) :\n",
    "            img = X[:,:,i]\n",
    "            #ax.axis('off')\n",
    "            ax.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)\n",
    "        \n",
    "        \n",
    "# avgpool = AvgPool2D(3,input_shape=conv.output_shape)\n",
    "# avgpool.Summary()\n",
    "# output = avgpool.feed(conv.output)\n",
    "# maxpool.plotImg(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Flatten` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 0 0]]\n",
      "[1 1 1 1 0 0]\n",
      "[[1 1 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "class Flatten :\n",
    "    \n",
    "    \"\"\"\n",
    "        Flatten class is used to convert data into single dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,input_shape=None,output_shape=None,__Name__='Flatten') : ### Constructor called when we create object \n",
    "        self.__Name__ = __Name__ ### Defining __Name__ variable with Flatten\n",
    "        self.__type__ = 'flat' ### Defining __type__ variable\n",
    "        self.input_shape = input_shape\n",
    "        self.A_F = None\n",
    "        re = 1\n",
    "        if output_shape is None :\n",
    "            for i in input_shape :\n",
    "                re *= i\n",
    "            self.output_shape = re\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        \n",
    "    def feed(self,X) : ### feed function is used to transforms data into single dimension\n",
    "        #self.input = X\n",
    "        self.output = X.ravel() ### ravel is used to convert data into single dimensoin or flattens data\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,X) :\n",
    "        return X.reshape(self.input_shape)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)\n",
    "        \n",
    "# flat = Flatten(input_shape = (2,3))\n",
    "# out = np.random.randint(0,2,(2,3))\n",
    "# print(out)\n",
    "# out = flat.feed(out)\n",
    "# print(out)\n",
    "# out = flat.feed_back(out)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dense` Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense :\n",
    "    \n",
    "    def __init__ (self,input_shape,N_F,A_F=None,wt=None,bias=None,output_shape=None,__Name__='Dense') :\n",
    "        \n",
    "        \"\"\"\n",
    "            Wt and Bias range [-2.4/No of nodes , 2.4/No of nodes] Proposed by range\n",
    "        \"\"\"\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'dense'\n",
    "        self.input_shape = input_shape\n",
    "        self.N_F = N_F\n",
    "        self.A_F = A_F\n",
    "        if output_shape is None :\n",
    "            self.output_shape = N_F\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        if wt is None :\n",
    "            #self.weights = np.random.uniform(self.input_shape, self.output_shape) / np.sqrt(self.input_shape + self.output_shape)\n",
    "            self.weights = np.random.uniform(-2.4/self.N_F,2.4/self.N_F,(self.input_shape, self.output_shape))\n",
    "        else :\n",
    "            self.weights = wt\n",
    "        if bias is None :\n",
    "            #self.bias = np.random.randn(1, self.output_shape) / np.sqrt(self.input_shape + self.output_shape)\n",
    "            self.bias = np.random.uniform(-2.4/ self.N_F,2.4/ self.N_F,(1, self.output_shape)) / self.N_F\n",
    "        else :\n",
    "            self.bias = bias\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        if X.shape[0] != 1 :\n",
    "            output = []\n",
    "            output.append(X)\n",
    "            self.input = np.array(output)\n",
    "        else :\n",
    "            self.input = X\n",
    "        self.output = np.matmul(X,self.weights) + self.bias\n",
    "        self.output = sklearn.preprocessing.normalize(self.output)\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=1e-03,deacy=1e-02):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        #output_error = output_error.mean(axis=0)*Z.T.shape[0]\n",
    "        weights_error = np.dot(Z.T, output_error)\n",
    "        self.weights = self.weights - learning_rate * weights_error\n",
    "        self.bias = self.bias - learning_rate * output_error\n",
    "#         self.weights = (1-decay)*self.weights - learning_rate * weights_error\n",
    "#         self.bias = (1-decay)*self.bias - learning_rate * output_error\n",
    "        return input_error\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential :\n",
    "    \n",
    "    \"\"\"\n",
    "        Sequential is a class which is used to stack layers of model and to fit , predict , predicting classes of our given i/p\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self) :\n",
    "        self.Layers = []\n",
    "        self.input_shape = None\n",
    "        self.Activations = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.error = []\n",
    "        self.val_error = []\n",
    "        self.id = 1\n",
    "        \n",
    "    def add(self,Layer) :\n",
    "        boo = False\n",
    "        for layer in self.Layers :\n",
    "            if Layer.__type__ == layer.__type__ :\n",
    "                boo = True\n",
    "                if '_' not in Layer.__Name__ :\n",
    "                    Layer.__Name__ += '_'+str(self.id)\n",
    "                name,k = Layer.__Name__.split('_')\n",
    "                Layer.__Name__ = name+'_'+str(int(k)+1)\n",
    "        if not boo :\n",
    "            if '_' not in Layer.__Name__ :\n",
    "                Layer.__Name__ += '_'+str(self.id)\n",
    "        \n",
    "        self.Layers.append(Layer)\n",
    "        if Layer.__type__ != 'activation' :\n",
    "            if self.input_shape is None :\n",
    "                self.input_shape = Layer.input_shape\n",
    "            self.output_shape = Layer.output_shape\n",
    "        if Layer.A_F is not None :\n",
    "            if Layer.A_F.lower() == 'softmax' :\n",
    "                self.Activations.append(Softmax())\n",
    "            elif Layer.A_F.lower() == 'sigmoid' :\n",
    "                self.Activations.append(Sigmoid())\n",
    "            else :\n",
    "                self.Activations.append(ReLU())\n",
    "        else :\n",
    "            self.Activations.append(None)\n",
    "        \n",
    "    def compile(self,loss='cross_entropy',metrics=['acc']) :\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def shuffle(self,input_,target) :\n",
    "        n = np.random.randint((len(input_),1))\n",
    "        c = 0\n",
    "        for i in n :\n",
    "            input_[c] , input_[i] = input_[i] , input_[c]\n",
    "            target[c] , target[i] = target[i] , target[c]\n",
    "            c += 1\n",
    "        return input_ , target\n",
    "        \n",
    "    def one_hot_encode(self,l) :\n",
    "        Labels = np.zeros(self.Layers[-1].output_shape)\n",
    "        Labels[l] = 1\n",
    "#         for i,label in enumerate(labels) :\n",
    "#             Labels[i][label] = 1\n",
    "        return Labels\n",
    "        \n",
    "    def fit(self,train_data,valid_data=None,validation_split=.1,epochs=10,lr=1e-02,decay=1e-03,batch_size=1) :\n",
    "        self.epochs = epochs\n",
    "        input_ , Total , target , No_of_outs = None , None , None , None\n",
    "        val_input , val_target = None , None\n",
    "        if train_data is None :\n",
    "            raise ValueError('Training Data Required')\n",
    "        else :\n",
    "            input_ = train_data[0]\n",
    "            Total = train_data[1]\n",
    "            target = Total\n",
    "            No_of_outs = len(set(target))\n",
    "        N = len(input_)\n",
    "        \n",
    "        if valid_data is None :\n",
    "            if validation_split != 0 :\n",
    "                n = int(len(input_)*(1-validation_split))\n",
    "                K = np.random.randint(0,N,(N))\n",
    "                for i in range(N-1) :\n",
    "                    train_data[0][K[i]] = train_data[0][K[i+1]]\n",
    "                    train_data[1][K[i]] = train_data[1][K[i+1]]\n",
    "                input_ , target = train_data[0][:n] , Total[:n]\n",
    "                val_input , val_target = train_data[0][n:] , Total[n:]\n",
    "        else :\n",
    "            val_input , val_target = valid_data[0] , valid_data[1]\n",
    "        \n",
    "        print('\\nModel Fitting\\n')\n",
    "        \n",
    "        N = len(input_)\n",
    "        \n",
    "#         input_ = preprocessing.normalize(input_,axis=0)\n",
    "#         val_input = preprocessing.normalize(val_input,axis=0)\n",
    "        \n",
    "        for ep in range(epochs) :\n",
    "            start_ep = time.time()\n",
    "            error = 0\n",
    "            acc = 0\n",
    "            input_ , target = self.shuffle(input_,target)\n",
    "            \n",
    "            print(f'\\nepoch : {ep+1}/{epochs}')\n",
    "            \n",
    "            for c,(X,Y) in enumerate(zip(input_,target)) :\n",
    "                \n",
    "                #print(f'\\r[','='*int(c*50/N),'>','.'*(50-int(c*50/N)),']'+f' Error : %.4f' %(error),end=\"\")\n",
    "                #print(c)\n",
    "                \n",
    "                \n",
    "                L_INPUTS , L_OUTPUTS ,  A_INPUTS , A_OUTPUTS = [] , [] , [] , []\n",
    "                \n",
    "                output = X\n",
    "                loss = None\n",
    "                out_err = None\n",
    "                \n",
    "                \"\"\"\n",
    "                    Forward Feeding [ Z = W*X + B ]\n",
    "                \"\"\"\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    L_INPUTS.append(output)\n",
    "                    output = layer.feed(output) # Feeding to Layer\n",
    "                    L_OUTPUTS.append(output)\n",
    "                    if activation is not None :\n",
    "                        A_INPUTS.append(output)\n",
    "                        output = activation.feed(output) # applying activation to output of the Layers\n",
    "                        A_OUTPUTS.append(output)\n",
    "                        \n",
    "                activation_output = self.Activations[-1].output # a-l\n",
    "                output = self.Layers[-1].output # z-l\n",
    "\n",
    "                \"\"\"\n",
    "                    Loss Calculation or Output Error\n",
    "                \"\"\"\n",
    "                \n",
    "                if self.loss == 'cross_entropy' :\n",
    "                    #loss = self.crossentropy(activation_output,Y)\n",
    "                    loss = self.cat_crossentropy(activation_output,Y)\n",
    "                    if math.isnan(loss) :\n",
    "                        model.epochs = ep-1\n",
    "                        return None\n",
    "                    grad_activation = self.Activations[-1].grad_feed(output)\n",
    "                    out_err = self.grad_crossentropy(output,Y)*grad_activation\n",
    "                \n",
    "                \"\"\"\n",
    "                    Backward Feeding\n",
    "                \"\"\"\n",
    "                \n",
    "                try :\n",
    "                    for i in range(1,len(self.Layers)-1) :\n",
    "                        if self.Layers[-i].__Name__[0] == 'D' :\n",
    "                            #print(self.Layers[-i].__Name__)\n",
    "                            if self.Activations[-i].__Name__ != 'Softmax' :\n",
    "                                out_err = self.Activations[-i].feed_back(A_INPUTS[-i],out_err,lr)\n",
    "                                #print(self.Activations[-i].__Name__)\n",
    "                            out_err = self.Layers[-i].feed_back(L_INPUTS[-i],out_err,lr,decay)\n",
    "                        else :\n",
    "                            break\n",
    "                except :\n",
    "                    pass\n",
    "                \n",
    "                error = np.mean(loss)\n",
    "                print('\\rerror=%f' % (error),end=\"\")\n",
    "                #print('\\rerror=%f -> c=%f' % (error,c),end=\"\")\n",
    "                \n",
    "            \"\"\"\n",
    "                Accuracy measuring at every epoch\n",
    "            \"\"\"\n",
    "            accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(input_, target)]) / len(input_)\n",
    "            self.acc.append(accuracy)\n",
    "            self.error.append(error)\n",
    "            \n",
    "            if 'acc' in self.metrics :\n",
    "                val_accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(val_input, val_target)]) / len(val_input)\n",
    "                self.val_acc.append(val_accuracy)\n",
    "                print(' acc=%f , val_acc=%f' % (accuracy , val_accuracy))\n",
    "            else :\n",
    "                print('\\racc=%f' % (accuracy))\n",
    "                \n",
    "            callback(model,fileName)\n",
    "            \n",
    "            end_ep = time.time()\n",
    "            \n",
    "            print(f'Time Taken for epoch {ep+1} : {end_ep-start_ep}s')\n",
    "            \n",
    "        return None\n",
    "            \n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "    \n",
    "    def mse_prime(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_pred.size\n",
    "    \n",
    "    def transfer_derivative(self,output):\n",
    "        return output * (1.0 - output)\n",
    "    \n",
    "    def binary_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -np.mean(GroundTruth*np.log(pred)+(1-GroundTruth)*np.log(1-pred))\n",
    "    \n",
    "    def binary_grad_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -((GroundTruth/pred)-((1-GroundTruth)/(1-pred)))\n",
    "    \n",
    "    def cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "#         a = Truth/pred\n",
    "#         b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "#         print(Truth,pred,a,b)\n",
    "#         print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "\n",
    "    def grad_cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        a = Truth/pred\n",
    "        b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "        print(Truth,pred,a,b)\n",
    "        print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "    \n",
    "    def crossentropy(self,logits,reference_answers):\n",
    "        return - logits[0][reference_answers] + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    def grad_crossentropy(self,logits,reference_answers):\n",
    "        ones_for_answers = np.zeros_like(logits)\n",
    "        ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "        softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "    \n",
    "    def showImg(self,X) :\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        outputs = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = X\n",
    "            for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                output = layer.feed(output)\n",
    "                if activation is not None :\n",
    "                    output = activation.feed(output)\n",
    "            outputs.append(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    output = layer.feed(output)\n",
    "                    if activation is not None :\n",
    "                        output = activation.feed(output)\n",
    "                outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def pred_class(self,X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = self.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = self.predict(output)\n",
    "                classes.append(np.argmax(output))\n",
    "            return np.array(classes)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        print('='*60)\n",
    "        print('Model Summary')\n",
    "        print('_'*60)\n",
    "        print('Layers',' '*(20-len('Layers')),'Input Shape',' '*(20-len('Input Shape')),'Output Shape',' '*(20-len('Output Shape')))\n",
    "        print('='*60)\n",
    "        for Layer in self.Layers :\n",
    "            if Layer.__type__ != 'activation' :\n",
    "                Layer.Summary()\n",
    "                print('_'*60)\n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Conv and Pool loading\n",
    "def LoadCP(X_train) :\n",
    "    X = []\n",
    "    conv = Conv2D(3,3,input_shape=X_train[0].shape,A_F='ReLU')\n",
    "    pool = MaxPool2D(5,input_shape=model.output_shape)\n",
    "    for i in X_train :\n",
    "        pass\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model Summary\n",
      "____________________________________________________________\n",
      "Layers                Input Shape           Output Shape         \n",
      "============================================================\n",
      "Conv2D_1              (100, 100, 3)         (96, 96, 3)\n",
      "____________________________________________________________\n",
      "MaxPool2D_1           (96, 96, 3)           (46, 46, 3)\n",
      "____________________________________________________________\n",
      "Flatten_1             (46, 46, 3)           6348\n",
      "____________________________________________________________\n",
      "Dense_1               6348                  100\n",
      "____________________________________________________________\n",
      "Dense_2               100                   2\n",
      "____________________________________________________________\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(3,5,input_shape=X_train[0].shape,A_F='ReLU'))\n",
    "model.add(MaxPool2D(5,input_shape=model.output_shape))\n",
    "model.add(Flatten(input_shape=model.output_shape))\n",
    "#model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=100,A_F='ReLU')) ### Input Layer\n",
    "#model.add(Dense(input_shape=model.output_shape,N_F=32,A_F='ReLU')) ## Hidden Layer\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=len(set(Y_train)),A_F='Sigmoid')) ### Output Layer\n",
    "model.compile(loss='cross_entropy',metrics=['acc'])\n",
    "\n",
    "model.Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fitting\n",
      "\n",
      "\n",
      "epoch : 1/200\n",
      "error=0.666601 acc=0.340000 , val_acc=0.320000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 1 : 171.40432476997375s\n",
      "\n",
      "epoch : 2/200\n",
      "error=0.669143 acc=0.345000 , val_acc=0.300000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 2 : 171.00619101524353s\n",
      "\n",
      "epoch : 3/200\n",
      "error=0.671532 acc=0.340000 , val_acc=0.300000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 3 : 177.44751358032227s\n",
      "\n",
      "epoch : 4/200\n",
      "error=0.673759 acc=0.340000 , val_acc=0.300000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 4 : 172.0234875679016s\n",
      "\n",
      "epoch : 5/200\n",
      "error=0.675842 acc=0.340000 , val_acc=0.300000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 5 : 168.9220471382141s\n",
      "\n",
      "epoch : 6/200\n",
      "error=0.677770 acc=0.350000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 6 : 169.39387130737305s\n",
      "\n",
      "epoch : 7/200\n",
      "error=0.679575 acc=0.345000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 7 : 168.96418285369873s\n",
      "\n",
      "epoch : 8/200\n",
      "error=0.681263 acc=0.340000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 8 : 168.31711149215698s\n",
      "\n",
      "epoch : 9/200\n",
      "error=0.682822 acc=0.340000 , val_acc=0.300000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 9 : 169.68001699447632s\n",
      "\n",
      "epoch : 10/200\n",
      "error=0.684267 acc=0.340000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 10 : 169.0463330745697s\n",
      "\n",
      "epoch : 11/200\n",
      "error=0.685605 acc=0.330000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 11 : 169.66147351264954s\n",
      "\n",
      "epoch : 12/200\n",
      "error=0.686867 acc=0.330000 , val_acc=0.280000\n",
      "CallBack :  Model_Check.obj Updated\n",
      "Time Taken for epoch 12 : 169.40125632286072s\n",
      "\n",
      "epoch : 13/200\n",
      "error=0.688011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ffeb7a258ae3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,validation_split=.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-36f84afb8609>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, valid_data, validation_split, epochs, lr, decay, batch_size)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mAccuracy\u001b[0m \u001b[0mmeasuring\u001b[0m \u001b[0mat\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-36f84afb8609>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mAccuracy\u001b[0m \u001b[0mmeasuring\u001b[0m \u001b[0mat\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-36f84afb8609>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivations\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-09721ba11677>\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK_S\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTRIDES\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;31m#print(X[i:i+self.K_S,j:j+self.K_S])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK_S\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK_S\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[1;31m# (98,10) , (100,12)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mh\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2665\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m-> 2667\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2668\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_data=(X_train,Y_train),epochs=epochs,lr=0.01,valid_data=(X_test,Y_test),batch_size=1) #,validation_split=.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Call Back to save model at every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(obj,fileName) :\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)\n",
    "    \n",
    "def loadModel(fileName) :\n",
    "    f = open(fileName, 'rb') \n",
    "    model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SaveModel(model,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadModel(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(range(model.epochs),model.acc,c='r',label='acc')\n",
    "plt.plot(range(model.epochs),model.val_acc,c='b',label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(model.epochs),model.error,c='black',label='error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(X_test)) :\n",
    "    print(model.pred_class(X_test[i]),Y_test[i])\n",
    "    if model.pred_class(X_test[i]) == Y_test[i] :\n",
    "        c += 1\n",
    "print(c*100/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.pred_class(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pred_class(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(X_train)) :\n",
    "    #print(model.pred_class(X_train[i]),Y_train[i])\n",
    "    if model.pred_class(X_train[i]) == Y_train[i] :\n",
    "        c += 1\n",
    "print(c*100/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[1]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[10]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Dir = 'D:/Data/Traffic Signs/Meta'\n",
    "for i in os.listdir(Dir) :\n",
    "    print(i)\n",
    "    img = cv2.imread(Dir+'/'+i)\n",
    "    img = cv2.resize(img,(size,size))/255.\n",
    "    test_data = []\n",
    "    test_data.append(img)\n",
    "    test_data = np.array(test_data)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    print(Labels[model.pred_class(test_data)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def MakeCoOrd(IMG_W=300,IMG_H=300,step=15,NumKernels=.1,start=25,kernelW=15) :\n",
    "    f = open('CoOrd.csv','w')\n",
    "    f.write(f'i,j,k,l\\n')\n",
    "    WIN_W = [i for i in range(kernelW*2,int(IMG_W*NumKernels),kernelW)] # kernels across width\n",
    "    WIN_H = [i for i in range(kernelW*2,int(IMG_W*NumKernels),kernelW)] # kernels across height\n",
    "    print(WIN_W,WIN_H)\n",
    "    WINs = []\n",
    "    for i in WIN_W :\n",
    "        for j in WIN_H :\n",
    "            WINs.append((i,j))\n",
    "    print(WINs)\n",
    "    for i in range(start,IMG_W-step,step) :\n",
    "        for j in range(start,IMG_H-step,step) :\n",
    "            for W in WINs :\n",
    "                Ww , Wh = W[0] , W[1]\n",
    "                a,b,c,d = i-Ww , j-Wh, i+Ww , j+Wh\n",
    "                if a < 0 :\n",
    "                    a = 0\n",
    "                if b < 0 :\n",
    "                    b = 0\n",
    "                if c > IMG_W :\n",
    "                    c = IMG_W\n",
    "                if d > IMG_H :\n",
    "                    d = IMG_H\n",
    "                #print(f'({a,b},{c,d})')\n",
    "                f.write(f'{a},{b},{c},{d}\\n')\n",
    "                \n",
    "IMG_SIZE=300\n",
    "STEP = 10\n",
    "MakeCoOrd(IMG_W=IMG_SIZE,IMG_H=int(IMG_SIZE/2),step=STEP,NumKernels=.3,start=50,kernelW=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROIS = []\n",
    "LOCS = []\n",
    "def ObjectDetector(path) :\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    OrgImg = img.copy()\n",
    "    data = pd.read_csv('CoOrd.csv')\n",
    "    for i,j,k,l in zip(data['i'],data['j'],data['k'],data['l']) :\n",
    "        im = img[j:l,i:k]\n",
    "        im = cv2.resize(im,(size,size))\n",
    "        LOCS.append([i,j,k,l])\n",
    "        ROIS.append(im)\n",
    "        \"\"\"try :\n",
    "            pred = PredVal(MODEL_BG , im)\n",
    "            #print(f'\\r {pred[1]} ' , end=\"\")\n",
    "            if pred[0] <= 0.1 :\n",
    "                pred = PredVal(MODEL_FG , im)\n",
    "                if pred[0] == 1.0 :\n",
    "                    img = drawRect(img,i,j,k,l,LabelNames[pred[1]])\n",
    "                    plt.imshow(img)\n",
    "                    plt.show()\n",
    "                    img = OrgImg.copy()\n",
    "        except :\n",
    "            pass\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pred_class(X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = model.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = model.predict(output)\n",
    "                classes.append(output)\n",
    "            return np.array(classes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = loadModel(fileName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def drawRect(img,i,j,k,l,label) :\n",
    "    img =  cv2.rectangle(img, (i,j), (k,l) , (200,200,200), 2)\n",
    "    #return cv2.putText(img, label , (i+1,l-r1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "ObjectDetector('D:/Data/TestData/Stop.jpg')\n",
    "print('Predicting')\n",
    "preds = pred_class(np.array(ROIS , dtype='float32'))\n",
    "print(f'\\n{datetime.datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_confd = 30\n",
    "img = cv2.imread('D:/Data/TestData/Stop.jpg')\n",
    "#img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img,(300,300))\n",
    "OrgImg = img.copy()\n",
    "for i,p in enumerate(preds) :\n",
    "    #ind = np.argsort(p)[::-1][0]\n",
    "    #print(p[0][0])\n",
    "    ind = np.argsort(p[0][0])\n",
    "    print(p[i][0][ind])\n",
    "    if p[0][0][ind] >= min_confd :\n",
    "        print(LOCS[i])\n",
    "        X = drawRect(img,LOCS[i][0],LOCS[i][1],LOCS[i][2],LOCS[i][3],'')\n",
    "        \n",
    "    plt.imshow(X)\n",
    "    plt.show()\n",
    "    img = OrgImg.copy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(Labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i,p in enumerate(preds) :\n",
    "    print(np.argsort(p[i]))\n",
    "    print(p[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[1,2,3]])\n",
    "x = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (w*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_x = np.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e__ = e_x / np.sum(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = []\n",
    "for i in range(len(e_x)) :\n",
    "    res = (e_x[i]*np.sum(e_x) - e_x[i]**2)/np.sum(e_x)**2\n",
    "    emp.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = wx+b\n",
    "E = -sum(T.log(y))\n",
    "dE/dW = -[T0*[1-(e**Y/sum(e**Y))]*X]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
