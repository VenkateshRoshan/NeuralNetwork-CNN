{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Signals Detection Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tnrange\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (30kmph)', 'Speed limit (60kmph)', 'Speed limit (100kmph)']\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "size = 50\n",
    "ReqLabels = [1,3,7]#,14]#,17,33,34,36,37]\n",
    "\n",
    "Train_Path = 'D:/Data/Traffic Signs/Train.csv'\n",
    "Test_Path = 'D:/Data/Traffic Signs/Test.csv'\n",
    "Meta_Path = 'D:/Data/Traffic Signs/Meta.csv'\n",
    "Labels_Path = 'D:/Data/Traffic Signs/Labels.csv'\n",
    "\n",
    "Labels = []\n",
    "labelData = pd.read_csv(Labels_Path)\n",
    "for i,j in zip(labelData['ClassId'] , labelData['SignName']) :\n",
    "    if i in ReqLabels :\n",
    "        Labels.append(j)\n",
    "        \n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(Meta_Path)\n",
    "NoOfLabels = len(data['Path'])\n",
    "print(NoOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 3: 0, 7: 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LoadData(Dir,typeLoad,count=100,Cou=2) :\n",
    "    data = pd.read_csv(Dir)\n",
    "    display(data.head())\n",
    "    X , Y = [] , []\n",
    "    for i,rx1,ry1,rx2,ry2,cId in zip(data['Path'],data['Roi.X1'],data['Roi.Y1'],data['Roi.X2'],data['Roi.Y2'],data['ClassId']) :\n",
    "        print(f'\\r{len(Y)}\\t\\t',end=\"\")\n",
    "        if cId in ReqLabels :\n",
    "            i = 'D:/Data/Traffic Signs/' + i\n",
    "            img = cv2.imread(i)\n",
    "            img = img[ry1:ry2,rx1:rx2]\n",
    "            img = cv2.resize(img,(size,size))\n",
    "#             datagen = ImageDataGenerator(rotation_range=5)\n",
    "#             it = datagen.flow(np.expand_dims(img,axis=0), batch_size=1)\n",
    "#             for l in range(Cou):\n",
    "#                 batch = it.next()\n",
    "#                 image = batch[0].astype('uint8')\n",
    "#                 X.append(image)\n",
    "#                 Y.append(ReqLabels.index(cId))\n",
    "#                 Count_Labels[cId] += 1\n",
    "#             datagen = ImageDataGenerator(brightness_range=[0.0,1.0])\n",
    "#             it = datagen.flow(np.expand_dims(img,axis=0), batch_size=1)\n",
    "#             for l in range(Cou):\n",
    "#                 batch = it.next()\n",
    "#                 image = batch[0].astype('uint8')\n",
    "#                 X.append(image)\n",
    "#                 Y.append(ReqLabels.index(cId))\n",
    "#                 Count_Labels[cId] += 1\n",
    "            if Count_Labels[cId] <= count-1 :\n",
    "                X.append(img)\n",
    "                Y.append(ReqLabels.index(cId))\n",
    "                if typeLoad == 'Train' or typeLoad == 'Test' :\n",
    "                    Count_Labels[cId] += 1\n",
    "        \n",
    "    return np.array(X)/255. , np.array(Y)\n",
    "\n",
    "\n",
    "X_train , Y_train = LoadData(Train_Path,'Train',count=200,Cou=1)\n",
    "print(Count_Labels)\n",
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "    \n",
    "print(Count_Labels)  \n",
    "\n",
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "    \n",
    "\n",
    "X_test , Y_test = LoadData(Test_Path,'Test',50,Cou=1)\n",
    "\n",
    "print(Count_Labels)\n",
    "\n",
    "Data = ( X_train , Y_train , X_test , Y_test , Labels )\n",
    "f = open(loc , 'wb')\n",
    "pickle.dump(Data , f)\n",
    "\n",
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape} , X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')\n",
    "\n",
    "print(set(Y_train) , set(Y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loc = 'train_test_2.0_fixed.obj'\n",
    "f = open(loc , 'rb')\n",
    "X_train , Y_train , X_test , Y_test , Labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (2762, 32, 32, 3), Y_train shape : (2762,)\n",
      "X_test shape : (1185, 32, 32, 3), Y_test shape : (1185,)\n"
     ]
    }
   ],
   "source": [
    "loc = 'D:/CNN_1.0/train_test_6.0_Size32_fixed.obj'\n",
    "f = open(loc , 'rb')\n",
    "X_train , Y_train , Labels = pickle.load(f)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, \n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"\"\"X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}\n",
    "X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Model_Conv_2.2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(obj,fileName) :\n",
    "    print('CallBack : ',fileName,'Updated')\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (2762, 32, 32, 3), Y_train shape : (2762,)\n",
      "X_test shape : (1185, 32, 32, 3), Y_test shape : (1185,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}\\nX_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speed limit (30kmph)',\n",
       " 'Speed limit (60kmph)',\n",
       " 'Stop',\n",
       " 'Turn right ahead',\n",
       " 'Turn left ahead',\n",
       " 'Negative']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'ReLU'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        return np.maximum(0,X)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        i = 0\n",
    "        for z in Z :\n",
    "            try :\n",
    "                grad = z\n",
    "                grad[z < 0] = 0\n",
    "                grad[z > 0] = 1\n",
    "                grad_output[i] = grad_output[i]*grad\n",
    "                i += 1\n",
    "            except Exception :\n",
    "                return grad_output\n",
    "        return grad_output\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        output = np.maximum(0,Y)\n",
    "        return output\n",
    "    \n",
    "class TanH :\n",
    "    def __init__(self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'TanH'\n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            output = np.tanh(x)\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "        \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        outs = []\n",
    "        for z in Z :\n",
    "            outs.append(1-np.power(np.tanh(z),2))\n",
    "        return np.array(outs)\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        output = np.tanh(Y)\n",
    "        return output\n",
    "        \n",
    "class Softmax :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Softmax'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            e_x = np.exp(x - np.max(x,\n",
    "                                    axis=1,\n",
    "                                    keepdims=True))\n",
    "            output = e_x/np.sum(e_x,\n",
    "                                axis=1,\n",
    "                                keepdims=True)\n",
    "            outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        e_x = np.exp(X - np.max(X,\n",
    "                                axis=1,\n",
    "                                keepdims=True))\n",
    "        out = (e_x/e_x.sum()) - ((e_x*e_x)/np.power(e_x.sum(),2))\n",
    "        return out\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        e_x = np.exp(Z - np.max(Z))\n",
    "        out = e_x/np.sum(e_x)\n",
    "        softmax = np.reshape(out, (1, -1))\n",
    "        grad_output = np.reshape(grad_output, (1, -1))\n",
    "        grad = (softmax * np.identity(softmax.size) - softmax.transpose() @ softmax)\n",
    "        return grad_output*grad\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        e_x = np.exp(Y-np.max(Y))\n",
    "        output = e_x/np.sum(e_x)\n",
    "        return output\n",
    "    \n",
    "class Sigmoid :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Sigmoid'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            output = 1/(1+np.exp(-x))\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        out = 1/(1+np.exp(-X))\n",
    "        return out*(1-out)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        out = 1/(1+np.exp(-Z))\n",
    "        grad = out*((1-out)**2)\n",
    "        return grad_output*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Conv2D :\n",
    "    \n",
    "    def __init__ (self,N_F,K_S,A_F,input_shape,STRIDES=1,pad=0) :\n",
    "        self.__Name__ = 'Conv2D'\n",
    "        self.__type__ = 'conv'\n",
    "        self.N_F = N_F\n",
    "        self.K_S = K_S\n",
    "        self.STRIDES = STRIDES\n",
    "        self.A_F = A_F\n",
    "        self.pad = pad\n",
    "        if (len(input_shape) == 2) :\n",
    "            input_shape = input_shape+(1,)\n",
    "        if input_shape[0] is not None :\n",
    "            self.input_shape = (None,) + input_shape\n",
    "        else :\n",
    "            self.input_shape = input_shape\n",
    "        #self.weights = np.random.normal(size=(self.N_F,self.input_shape[-1],self.K_S,self.K_S))\n",
    "        self.weights = np.random.randint(-1,2,(self.N_F,self.input_shape[-1],self.K_S,self.K_S))\n",
    "        self.W = int((self.input_shape[1]-self.K_S+2*self.pad)/self.STRIDES) + 1\n",
    "        self.H = int((self.input_shape[2]-self.K_S+2*self.pad)/self.STRIDES) + 1\n",
    "        self.D = self.N_F\n",
    "        self.bias = np.zeros((self.N_F))\n",
    "        self.output_shape = (None,) + (self.W,self.H,self.D)\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        self.mdw = np.zeros((self.input_shape[1], self.output_shape[1])) \n",
    "        self.mdb = np.zeros((1,self.output_shape[1]))\n",
    "        \n",
    "        self.vdw = np.zeros((self.input_shape[1], self.output_shape[1])) \n",
    "        self.vdb = np.zeros((1,self.output_shape[1]))\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            if self.pad >0 :\n",
    "                x_ = np.zeros(((x.shape[0]+self.pad*2),x.shape[1]+self.pad*2,x.shape[2]))\n",
    "                x_[self.pad:-self.pad,self.pad:-self.pad] = x\n",
    "                x = x_\n",
    "            output = np.zeros((self.W,self.H,self.D))\n",
    "            h = 0\n",
    "            for i in range(0,self.input_shape[1],self.STRIDES) :\n",
    "                w = 0\n",
    "                for j in range(0,self.input_shape[2],self.STRIDES) :\n",
    "                    cur_reg = x[i:i+self.K_S,j:j+self.K_S].T*self.weights\n",
    "                    output[h,w] = np.sum(cur_reg,axis=(1,2,3)) + self.bias\n",
    "                    w += 1\n",
    "                h += 1\n",
    "            outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-02],decay=1e-03,opt='sgd',b1=.9,b2=.999) :\n",
    "        outs = []\n",
    "#         _,i_c,i_dim,__ = output_error.shape\n",
    "#         lr = learning_rate[np.random.randint(len(learning_rate))]\n",
    "#         for z,out_err in zip(Z,output_error) :\n",
    "#             d_op = np.zeros(z.shape)\n",
    "#             d_conv = np.zeros(self.weights.shape)\n",
    "#             d_bias = np.zeros(self.bias.shape)\n",
    "#             # dX[h:h+f, w:w+f] += W * dH(h,w)\n",
    "#             for i in range(0,i_c) :\n",
    "#                 for j in range(0,i_dim) :\n",
    "#                     for c in range(len(out_err[i,j])) :\n",
    "#                         d_conv[c] += (z[i:i+self.K_S,j:j+self.K_S] * out_err[i,j][c]).T\n",
    "#             d_bias = np.sum(out_err,axis=(0,1))\n",
    "#             self.weights = self.weights - lr * d_conv\n",
    "#             self.bias = self.bias - lr * d_bias\n",
    "# #             self.Batch_W.append(weights)\n",
    "# #             self.Batch_B.append(bias)\n",
    "# #             outs.append(d_op)\n",
    "# #         self.weights = np.mean(self.Batch_W,axis=0)\n",
    "# #         self.bias = np.mean(self.Batch_B,axis=0)\n",
    "# #         self.Batch_W = []\n",
    "# #         self.Batch_B = []\n",
    "        \n",
    "        return np.array(outs)\n",
    "\n",
    "    def predict(self,Y) :\n",
    "        output = np.zeros((self.W,self.H,self.D))\n",
    "        h = 0\n",
    "        if self.pad >0 :\n",
    "            x_ = np.zeros(((Y.shape[0]+self.pad*2),Y.shape[1]+self.pad*2,Y.shape[2]))\n",
    "            x_[self.pad:-self.pad,self.pad:-self.pad] = Y\n",
    "            Y = x_\n",
    "        for i in range(0,self.input_shape[1],self.STRIDES) :\n",
    "            w = 0\n",
    "            for j in range(0,self.input_shape[2],self.STRIDES) :\n",
    "                cur_reg = Y[i:i+self.K_S,j:j+self.K_S].T*self.weights\n",
    "                output[h,w] = np.sum(cur_reg,axis=(1,2,3)) + self.bias\n",
    "                w += 1\n",
    "            h += 1\n",
    "        return output\n",
    "    \n",
    "    def plotImg(self,X=None,figSize=(5,5)) :\n",
    "        if X is None :\n",
    "            return\n",
    "        for x in X :\n",
    "            Filter_SIZE = int(x.shape[-1]**(1/2))\n",
    "            _, axs = plt.subplots(Filter_SIZE,Filter_SIZE, figsize=figSize)\n",
    "            axs = axs.flatten()\n",
    "            for i , ax in enumerate(axs) :\n",
    "                img = x[:,:,i]\n",
    "                ax.axis('off')\n",
    "                ax.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)\n",
    "        \n",
    "# img = X_train[10]\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# conv = Conv2D(16,3,'ReLU',input_shape=(img.shape[0],img.shape[1]),STRIDES=2,pad=1)\n",
    "\n",
    "# conv.Summary()\n",
    "# img = conv.feed(np.expand_dims(img,axis=0))\n",
    "# conv.plotImg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D :\n",
    "    \n",
    "    def __init__ (self,K_S,input_shape,STRIDES=2,pad=0) :\n",
    "        self.__Name__ = 'MaxPool2D'\n",
    "        self.__type__ = 'pool'\n",
    "        self.K_S = K_S\n",
    "        self.STRIDES = STRIDES\n",
    "        self.A_F = None\n",
    "        self.pad = pad\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = (None,) + (int((self.input_shape[1]-self.K_S+1)/self.STRIDES),int((self.input_shape[2]-self.K_S+1)/self.STRIDES),self.input_shape[-1])\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        self.weights = np.zeros((self.input_shape[1:]))\n",
    "        self.bias = np.zeros((self.output_shape[1:]))\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            if self.pad >0 :\n",
    "                x_ = np.zeros(((x.shape[0]+self.pad*2),x.shape[1]+self.pad*2,x.shape[2]))\n",
    "                x_[self.pad:-self.pad,self.pad:-self.pad] = x\n",
    "                x = x_\n",
    "            W,H,D = self.output_shape[1:]\n",
    "            output = np.zeros((W,H,D))\n",
    "            w , h = 0 , 0\n",
    "            for j in range(0,self.input_shape[1]-self.K_S,self.STRIDES) :\n",
    "                for i in range(0,self.input_shape[2]-self.K_S,self.STRIDES) :\n",
    "                    output[w,h] = np.max(x[j:j+self.K_S,i:i+self.K_S].T,axis=(1,2))\n",
    "                    h += 1\n",
    "                h = 0\n",
    "                w += 1\n",
    "            outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def create_mask_from_window(self,x):\n",
    "        mask = x == np.max(x)\n",
    "        return mask\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-03],decay=1e-03,opt='sgd') :\n",
    "        outs = []\n",
    "#         _,W,H,C = output_error.shape\n",
    "#         for z,out_err in zip(Z,output_error) :\n",
    "#             d_op = np.zeros(z.shape)\n",
    "#             for x in range(0,W) :\n",
    "#                 for y in range(0,H) :\n",
    "#                     for c in range(C) :\n",
    "#                         roi = z[x:x+self.K_S,y:y+self.K_S,c]\n",
    "#                         mask = self.create_mask_from_window(roi)\n",
    "#                         #update_y ,update_x = np.unravel_index(np.argmax(roi),roi.shape)\n",
    "#                         d_op[x:x+self.K_S,y:y+self.K_S,c] = np.multiply(mask, out_err[x,y,c]) #output_error[out_y,out_x]\n",
    "#             outs.append(d_op)\n",
    "        return np.array(outs)\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        W,H,D = self.output_shape[1:]\n",
    "        output = np.zeros((W,H,D))\n",
    "        w , h = 0 , 0\n",
    "        for i in range(0,self.input_shape[1]-self.K_S,self.STRIDES) :\n",
    "            for j in range(0,self.input_shape[2]-self.K_S,self.STRIDES) :\n",
    "                output[w,h] = np.max(Y[j:j+self.K_S,i:i+self.K_S].T,axis=(1,2))\n",
    "                h += 1\n",
    "            h = 0\n",
    "            w += 1\n",
    "        return output\n",
    "    \n",
    "    def plotImg(self,X=None) :\n",
    "        if X is None :\n",
    "            return\n",
    "        for x in X :\n",
    "            Filter_SIZE = int(x.shape[-1]**(1/2))\n",
    "            _, axs = plt.subplots(Filter_SIZE,Filter_SIZE, figsize=(8,8))\n",
    "            axs = axs.flatten()\n",
    "            for i , ax in enumerate(axs) :\n",
    "                img = x[:,:,i]\n",
    "                ax.axis('off')\n",
    "                ax.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten :\n",
    "    \n",
    "    \"\"\"\n",
    "        Flatten class is used to convert data into single dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,input_shape=None,output_shape=None,__Name__='Flatten') : ### Constructor called when we create object \n",
    "        self.__Name__ = __Name__ ### Defining __Name__ variable with Flatten\n",
    "        self.__type__ = 'flat' ### Defining __type__ variable\n",
    "        if input_shape[0] is not None :\n",
    "            self.input_shape = (None,) + input_shape\n",
    "        else :\n",
    "            self.input_shape = input_shape\n",
    "        self.A_F = None\n",
    "        re = 1\n",
    "        if output_shape is None :\n",
    "            for i in self.input_shape[1:] :\n",
    "                re *= i\n",
    "            self.output_shape = (None,re)\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        self.weights = np.zeros((self.input_shape[1:]))\n",
    "        self.bias = np.zeros((self.output_shape[1:]))\n",
    "        \n",
    "    def feed(self,X) : ### feed function is used to transforms data into single dimension\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            output = x.ravel() ### ravel is used to convert data into single dimensoin or flattens data\n",
    "            outputs.append(np.expand_dims(output,axis=0))\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-03],decay=1e-03,opt='sgd') :\n",
    "        outs = []\n",
    "        for z,out_err in zip(Z,output_error) :\n",
    "            outs.append(out_err.reshape(self.input_shape[1:]))\n",
    "        return np.array(outs)\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        return Y.ravel()\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Dropout :\n",
    "    def __init__(self,input_shape=None,drop=.5,__Name__ = 'Dropout',A_F=None) :\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'drop'\n",
    "        self.N_F = drop\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = self.input_shape\n",
    "        self.weights = np.random.binomial(1, drop, self.input_shape[1:]) / drop\n",
    "        self.A_F = A_F\n",
    "        self.Batch_W = []\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            outputs.append(x*self.weights.T)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-03],decay=1e-03,opt='sgd') :\n",
    "        return output_error * Z / self.N_F\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        return Y*self.weights\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense :\n",
    "    \n",
    "    def __init__ (self,input_shape,N_F,A_F=None,wt=None,bias=None,output_shape=None,__Name__='Dense') :\n",
    "        \n",
    "        \"\"\"\n",
    "            Wt and Bias range [-2.4/No of nodes , 2.4/No of nodes] Proposed by range\n",
    "        \"\"\"\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'dense'\n",
    "        self.input_shape = input_shape\n",
    "        self.N_F = N_F\n",
    "        self.A_F = A_F\n",
    "        \n",
    "        if output_shape is None :\n",
    "            self.output_shape = (None,N_F)\n",
    "        else :\n",
    "            self.output_shape = (None,) + output_shape\n",
    "        if wt is None :\n",
    "            #self.weights = np.random.uniform(-2.4/self.N_F,2.4/self.N_F,(self.input_shape[1], self.output_shape[1]))* np.sqrt(2/self.N_F) \n",
    "            self.weights = 0.1*np.random.randn(self.input_shape[1] , self.output_shape[1]) / np.sqrt(self.input_shape[1] + self.output_shape[1])\n",
    "        else :\n",
    "            self.weights = wt\n",
    "        if bias is None :\n",
    "            #self.bias = np.random.uniform(-2.4/ self.N_F,2.4/ self.N_F,(1, self.output_shape[1]))\n",
    "            self.bias = np.random.randn(1,self.output_shape[1]) / (self.input_shape[1] + self.output_shape[1])\n",
    "        else :\n",
    "            self.bias = bias\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        outputs = []\n",
    "        for x in X :\n",
    "            output = np.matmul(x,self.weights) + self.bias\n",
    "            outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-03],decay=1e-08,opt='sgd',b1=.9,b2=.999,mom=.02,n_iter=2):\n",
    "        outs = []\n",
    "        \n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        weights , bias = self.weights , self.bias\n",
    "        \n",
    "        lr = learning_rate[np.random.randint(len(learning_rate))]\n",
    "        \n",
    "        for z,out_err in zip(Z,output_error) :\n",
    "            \n",
    "            self.mdw = np.zeros((self.input_shape[1], self.output_shape[1])) \n",
    "            self.mdb = np.zeros((1,self.output_shape[1]))\n",
    "\n",
    "            self.vdw = np.zeros((self.input_shape[1], self.output_shape[1])) \n",
    "            self.vdb = np.zeros((1,self.output_shape[1]))\n",
    "            \n",
    "            b1 = .9\n",
    "            \n",
    "            outs.append(np.dot(out_err,weights.T))\n",
    "            \n",
    "            weights_error = np.dot(z.T, out_err)\n",
    "            \n",
    "            if opt.lower() == 'gd' :\n",
    "                self.weights = self.weights - lr * weights_error\n",
    "                self.bias = self.bias - lr * out_err\n",
    "                \n",
    "            elif opt.lower() == 'sgd' :\n",
    "                self.weights -= lr * weights_error - (1-b1) * weights_error * weights_error\n",
    "                self.bias -= lr * out_err - (1-b1) * out_err * out_err\n",
    "                \n",
    "            elif opt.lower() == 'rmsprop' :\n",
    "                self.vdw , self.vdb = RMSProp(weights_error,out_err,self.vdw,self.vdb)\n",
    "                self.weights -= (lr/(np.sqrt(self.vdw + decay))) * weights_error\n",
    "                self.bias -= (lr/(np.sqrt(self.vdb + decay))) * out_err\n",
    "            \n",
    "            elif opt.lower() == 'adam' :\n",
    "                \n",
    "                for t in range(n_iter) :\n",
    "                    self.mdw,self.mdb,self.vdw,self.vdb,mdw_corr,mdb_corr,vdw_corr,vdb_corr = AdamOptimizer(weights_error,\n",
    "                                                                                                            out_err,\n",
    "                                                                                                            self.mdw,self.mdb,\n",
    "                                                                                                            self.vdw,self.vdb,\n",
    "                                                                                                            t,b1=b1)\n",
    "\n",
    "                    self.weights = self.weights - (lr/(np.sqrt(vdw_corr+decay))) * mdw_corr\n",
    "                    self.bias = self.bias - (lr/(np.sqrt(vdb_corr+decay))) * mdb_corr\n",
    "                    \n",
    "                    if n_iter > 1 :\n",
    "                        \n",
    "                        b1 *= (1-decay)\n",
    "\n",
    "                        out = np.matmul(z,weights) + bias\n",
    "\n",
    "                        weights_error = np.dot(z.T, out_err)\n",
    "                        \n",
    "        return np.array(outs)\n",
    "    \n",
    "    def predict(self,Y) :\n",
    "        return np.matmul(Y,self.weights) + self.bias\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSProp(dw,db,vdw,vdb,b1=.9) :\n",
    "    \n",
    "    vdw = b1 * vdw + (1-b1) * dw ** 2\n",
    "    vdb = b1 * vdb + (1-b1) * db ** 2\n",
    "    \n",
    "    return (vdw,vdb)\n",
    "\n",
    "def AdamOptimizer(dw,db,mdw,mdb,vdw,vdb,n_iter,b1=.9,b2=.999) :\n",
    "    \n",
    "    mdw = b1 * mdw + (1-b1) * dw\n",
    "    mdb = b1 * mdb + (1-b1) * db\n",
    "    \n",
    "    vdw_ = b2 * vdw + (1-b2) * dw ** 2\n",
    "    vdb_ = b2 * vdb + (1-b2) * db ** 2\n",
    "    \n",
    "    vdw = np.maximum(vdw_,vdw)\n",
    "    vdb = np.maximum(vdb_,vdb)\n",
    "    \n",
    "    mdw_corr = mdw / (1-np.power(b1,n_iter+1))\n",
    "    mdb_corr = mdb / (1-np.power(b1,n_iter+1))\n",
    "    \n",
    "    vdw_corr = vdw / (1-np.power(b2,n_iter+1))\n",
    "    vdb_corr = vdb / (1-np.power(b2,n_iter+1))\n",
    "    \n",
    "    return (mdw,mdb,vdw,vdb,mdw_corr,mdb_corr,vdw_corr,vdb_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotAcc(model) : ### Accuracy Plot\n",
    "    plt.plot(range(model.ep),model.acc,c='b',label='acc')\n",
    "    plt.plot(range(model.ep),model.val_acc,c='r',label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def PlotError(model) : ### Error Plot\n",
    "    plt.plot(range(model.ep),model.error,c='b',label='loss')\n",
    "    plt.plot(range(model.ep),model.val_error,c='r',label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential :\n",
    "    \n",
    "    \"\"\"\n",
    "        Sequential is a class which is used to stack layers of model and to fit , predict , predicting classes of our given i/p\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self) :\n",
    "        self.Layers = []\n",
    "        self.input_shape = None\n",
    "        self.Activations = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.error = []\n",
    "        self.val_error = []\n",
    "        self.id = 1\n",
    "        self.ep = 1\n",
    "        \n",
    "    def add(self,Layer) :\n",
    "        boo = False\n",
    "        for layer in self.Layers :\n",
    "            if Layer.__type__ == layer.__type__ :\n",
    "                boo = True\n",
    "                if '_' not in Layer.__Name__ :\n",
    "                    Layer.__Name__ += '_'+str(self.id)\n",
    "                name,k = Layer.__Name__.split('_')\n",
    "                Layer.__Name__ = name+'_'+str(int(k)+1)\n",
    "        if not boo :\n",
    "            if '_' not in Layer.__Name__ :\n",
    "                Layer.__Name__ += '_'+str(self.id)\n",
    "        \n",
    "        self.Layers.append(Layer)\n",
    "        if Layer.__type__ != 'activation' :\n",
    "            if self.input_shape is None :\n",
    "                self.input_shape = Layer.input_shape\n",
    "            self.output_shape = Layer.output_shape\n",
    "        if Layer.A_F is not None :\n",
    "            if Layer.A_F.lower() == 'softmax' :\n",
    "                self.Activations.append(Softmax())\n",
    "            elif Layer.A_F.lower() == 'sigmoid' :\n",
    "                self.Activations.append(Sigmoid())\n",
    "            elif Layer.A_F.lower() == 'tanh' :\n",
    "                self.Activations.append(TanH())\n",
    "            else :\n",
    "                self.Activations.append(ReLU())\n",
    "        else :\n",
    "            self.Activations.append(None)\n",
    "    \n",
    "    def ShuffleData(self,X,Y) :\n",
    "        order = np.random.randint(0,len(Y),(len(Y)))\n",
    "        for i in range(len(Y)-1) :\n",
    "            X[order[i]] , X[order[i+1]] = X[order[i+1]] , X[order[i]]\n",
    "            Y[order[i]] , Y[order[i+1]] = Y[order[i+1]] , Y[order[i]]\n",
    "        return (X , Y)\n",
    "    \n",
    "    def SplitData(self,X,Y,split) :\n",
    "        input_data , output_data , val_input_data , val_output_data = None , None , None , None\n",
    "        N = int(len(Y) * (1-split))\n",
    "        while True :\n",
    "            X , Y = self.ShuffleData(X,Y)\n",
    "            if set(Y[:N]) != set(Y[N:]) :\n",
    "                X ,Y = self.ShuffleData(X,Y)\n",
    "            else :\n",
    "                input_data , output_data = X[:N] , Y[:N]\n",
    "                val_input_data , val_output_data = X[N:] , Y[N:]\n",
    "                break\n",
    "        return (input_data , output_data , val_input_data , val_output_data)\n",
    "        \n",
    "    def compile(self,optimizer='sgd',loss='cross_entropy',metrics=['acc']) :\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def one_hot_encode(self,l) :\n",
    "        Labels = np.zeros(self.Layers[-1].output_shape[1:])\n",
    "        Labels[l] = 1\n",
    "#         for i,label in enumerate(labels) :\n",
    "#             Labels[i][label] = 1\n",
    "\n",
    "        return Labels\n",
    "    \n",
    "    def fit(self,train_data,valid_data=None,validation_split=.1,epochs=10,lr=[1e-02],decay=1e-03,batch_size=8,model_updation_epoch=2,PlotView=10,Labels=None) :\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        input_data , output_data = None , None\n",
    "        val_input_data , val_target_data = None , None\n",
    "        if train_data is None :\n",
    "            raise ValueError('Training Data Required')\n",
    "        else :\n",
    "            input_data = train_data[0]\n",
    "            output_data = train_data[1]\n",
    "        N = len(input_data)\n",
    "        \n",
    "        if valid_data is None :\n",
    "            input_data , output_data , val_input_data , val_output_data = self.SplitData(input_data , output_data , validation_split)\n",
    "        else :\n",
    "            val_input_data , val_output_data = valid_data[0] , valid_data[1]\n",
    "        \n",
    "        if Labels is not None :\n",
    "            self.Labels = Labels\n",
    "        \n",
    "        print('\\nModel Fitting\\n')\n",
    "        \n",
    "        N = len(output_data)\n",
    "        \n",
    "        for ep in range(epochs) :\n",
    "#             self.Layers[0].plotImg(self.Layers[0].feed(np.expand_dims(input_data[0],axis=0)))\n",
    "            model.ep = ep + 1\n",
    "            start_ep = time.time()\n",
    "            error = 0\n",
    "            acc = 0\n",
    "            print(f'\\nepoch : {ep+1}/{epochs}')\n",
    "            \n",
    "            for b,batch in enumerate(tnrange(0,N-batch_size+1,batch_size,desc='batch')) :\n",
    "                loss = None\n",
    "                X , Y = input_data[batch:batch+batch_size] , output_data[batch : batch+batch_size]\n",
    "                \n",
    "                \"\"\"\n",
    "                    Feed Forward\n",
    "                \"\"\"\n",
    "                \n",
    "                outputs = X\n",
    "                \n",
    "                outs = {i.__Name__ : {'lay':None,'act':None} for i in self.Layers}\n",
    "                ins = {i.__Name__ : {'lay':None,'act':None} for i in self.Layers}\n",
    "                \n",
    "                for lay , act in zip( self.Layers , self.Activations ) :\n",
    "                    ins[lay.__Name__]['lay'] = outputs\n",
    "                    outputs = lay.feed(outputs)\n",
    "                    outs[lay.__Name__]['lay'] = outputs\n",
    "                    if act is not None :\n",
    "                        ins[lay.__Name__]['act'] = outputs\n",
    "                        outputs = act.feed(outputs)\n",
    "                        outs[lay.__Name__]['act'] = outputs\n",
    "                    else :\n",
    "                        ins[lay.__Name__]['act'] = outputs\n",
    "                        outs[lay.__Name__]['act'] = outputs\n",
    "                        \n",
    "                        \n",
    "                \"\"\"\n",
    "                    Loss\n",
    "                \"\"\"\n",
    "                \n",
    "                out_errs = []\n",
    "                losses = []\n",
    "                if self.loss == 'cross_entropy' :\n",
    "                    for i,j,k in zip(outs[self.Layers[-1].__Name__]['act'] , Y , outs[self.Layers[-1].__Name__]['lay']) :\n",
    "                        loss = self.crossentropy(i,j)#,k)\n",
    "                        losses.append(loss)\n",
    "                        print('\\rLoss : %f \\t' % (loss) , end=\"\")\n",
    "                        \n",
    "                        if math.isnan(loss) :\n",
    "                            return None\n",
    "                        \n",
    "                        #grad_activation = self.Activations[-1].grad_feed(k)\n",
    "                        out_err = self.grad_crossentropy(k,j)#*grad_activation\n",
    "                        \n",
    "                        out_errs.append(np.expand_dims(out_err,axis=0))\n",
    "                        \n",
    "                out_errs = np.array(out_errs)\n",
    "                \n",
    "                print('\\rLoss : %f' % (np.mean(losses)) , end=\"\")\n",
    "                \n",
    "                \"\"\"\n",
    "                    Backward Feed\n",
    "                \"\"\"\n",
    "                \n",
    "                for i in range(1,len(self.Layers)-1) :\n",
    "                    nam = self.Layers[-i].__Name__\n",
    "                    na = self.Activations[-i]\n",
    "                    abcd = time.time()\n",
    "                    if na is not None and na.__Name__ != 'Softmax' :\n",
    "                        out_errs = self.Activations[-i].feed_back(ins[nam]['act'],out_errs,lr)\n",
    "                    out_errs = self.Layers[-i].feed_back(ins[nam]['lay'],out_errs,lr,decay,opt=self.optimizer)\n",
    "\n",
    "            error = loss\n",
    "    \n",
    "            accuracy = sum([y == np.argmax(model.predict(x)[0]) for x, y in zip(input_data, output_data)]) / N\n",
    "            \n",
    "            ac , loss = [] , []\n",
    "            \n",
    "            for x, y in zip(val_input_data, val_output_data) :\n",
    "                out,lay_out = model.predict(x)\n",
    "                if y == np.argmax(out) :\n",
    "                    ac.append(1)\n",
    "                else :\n",
    "                    ac.append(0)\n",
    "                \n",
    "            ac = np.mean(ac)\n",
    "            \n",
    "            print('\\racc=%f , val_acc=%f' % (accuracy ,ac))\n",
    "        \n",
    "            if ep == 0 :\n",
    "                callback(model,fileName)\n",
    "            else :\n",
    "                if max(model.acc) < accuracy :\n",
    "                    callback(model,fileName)\n",
    "                    \n",
    "            self.acc.append(accuracy)\n",
    "            self.val_acc.append(ac)\n",
    "            \n",
    "            self.error.append(error)\n",
    "            self.val_error.append(loss)\n",
    "            \n",
    "            if not (ep+1)%PlotView :\n",
    "                PlotAcc(self)\n",
    "#                 PlotError(self)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "    \n",
    "    def mse_prime(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_pred.size\n",
    "    \n",
    "    def transfer_derivative(self,output):\n",
    "        return output * (1.0 - output)\n",
    "    \n",
    "    def binary_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -np.mean(GroundTruth*np.log(pred)+(1-GroundTruth)*np.log(1-pred))\n",
    "    \n",
    "    def binary_grad_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -((GroundTruth/pred)-((1-GroundTruth)/(1-pred)))\n",
    "    \n",
    "    def cat_crossentropy(self,pred,Truth,out) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        return np.dot(Truth.ravel()/(pred.ravel()+1e-8) , self.Activations[-1].grad_feed(out).ravel())\n",
    "\n",
    "    def grad_cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        a = Truth/pred\n",
    "        b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "    \n",
    "    def crossentropy(self,logits,reference_answers) :\n",
    "        return - logits[0][reference_answers] + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    def grad_crossentropy(self,logits,reference_answers):\n",
    "        logits = np.ravel(logits)\n",
    "        ones_for_answers = np.zeros_like(logits)\n",
    "        ones_for_answers[reference_answers] = 1\n",
    "        e_x = np.exp(logits-np.max(logits))\n",
    "        softmax = e_x / e_x.sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "    \n",
    "    def showImg(self,X) :\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        outputs = []\n",
    "        lay_out = None\n",
    "        if X.shape == model.input_shape[1:] :\n",
    "            output = X\n",
    "            for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                output = layer.predict(output)\n",
    "                lay_out = output\n",
    "                if activation is not None :\n",
    "                    output = activation.predict(output)\n",
    "            outputs.append(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    output = layer.predict(output)\n",
    "                    if activation is not None :\n",
    "                        output = activation.feed(output)\n",
    "                outputs.append(output)\n",
    "        return np.array(outputs) , lay_out\n",
    "    \n",
    "    def pred_class(self,X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = self.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = self.predict(output)\n",
    "                classes.append(np.argmax(output))\n",
    "            return np.array(classes)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        print('='*60)\n",
    "        print('Model Summary')\n",
    "        print('_'*60)\n",
    "        print('Layers',' '*(20-len('Layers')),'Input Shape',' '*(20-len('Input Shape')),'Output Shape',' '*(20-len('Output Shape')))\n",
    "        print('='*60)\n",
    "        for Layer in self.Layers :\n",
    "            if Layer.__type__ != 'activation' :\n",
    "                Layer.Summary()\n",
    "                print('_'*60)\n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (2762, 32, 32, 3), Y_train shape : (2762,)\n",
      "X_test shape : (1185, 32, 32, 3), Y_test shape : (1185,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}\n",
    "X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model Summary\n",
      "____________________________________________________________\n",
      "Layers                Input Shape           Output Shape         \n",
      "============================================================\n",
      "Conv2D_1              (None, 32, 32, 3)     (None, 16, 16, 16)\n",
      "____________________________________________________________\n",
      "MaxPool2D_1           (None, 16, 16, 16)    (None, 7, 7, 16)\n",
      "____________________________________________________________\n",
      "Flatten_1             (None, 7, 7, 16)      (None, 784)\n",
      "____________________________________________________________\n",
      "Dense_1               (None, 784)           (None, 6)\n",
      "____________________________________________________________\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "### Model Initiating\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,3,input_shape=X_train[0].shape,A_F='ReLU',STRIDES=2,pad=1))\n",
    "# model.add(Conv2D(32,3,input_shape=model.output_shape,A_F='ReLU'))\n",
    "model.add(MaxPool2D(3,input_shape=model.output_shape))\n",
    "\n",
    "# # model.add(Conv2D(64,3,input_shape=model.output_shape,A_F='ReLU'))\n",
    "# model.add(MaxPool2D(3,input_shape=model.output_shape,pad=1))\n",
    "\n",
    "model.add(Flatten(input_shape=model.output_shape))\n",
    "\n",
    "# model.add(Flatten(input_shape=X_train[0].shape))\n",
    "\n",
    "# model.add(Dense(input_shape=model.output_shape,N_F=100,A_F='ReLU'))\n",
    "\n",
    "# model.add(Dropout(input_shape=model.output_shape))\n",
    "\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=len(set(Y_train)),A_F='Softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='cross_entropy',metrics=['acc'])\n",
    "\n",
    "model.Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fitting\n",
      "\n",
      "\n",
      "epoch : 1/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c6f2602ac94fbaa675d638a83cc843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='batch', max=2762.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.015418 \t"
     ]
    }
   ],
   "source": [
    "model = model.fit(train_data=(X_train,Y_train),\n",
    "                  epochs=50,\n",
    "                  valid_data=(X_test,Y_test),\n",
    "                  lr=[1e-05],\n",
    "                  decay=1e-08,\n",
    "                  batch_size=1,\n",
    "                  Labels=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_train[0])\n",
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
