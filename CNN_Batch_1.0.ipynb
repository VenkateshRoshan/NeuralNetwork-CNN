{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import normalize\n",
    "from tqdm.notebook import tnrange"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "(X_train,Y_train) , (X_test,Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train , X_test = X_train/255. , X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "size = 100\n",
    "#ReqLabels = [1,3,5,7,14]#,17,19,20,26,33,34,36,37,38,39]\n",
    "ReqLabels = [1,3,5,7,14,17,26,33,34,36,37]\n",
    "#ReqLabels = [1,14,38,39]\n",
    "Train_Path = 'D:/Data/Traffic Signs/Train.csv'\n",
    "Test_Path = 'D:/Data/Traffic Signs/Test.csv'\n",
    "Meta_Path = 'D:/Data/Traffic Signs/Meta.csv'\n",
    "Labels_Path = 'D:/Data/Traffic Signs/Labels.csv'\n",
    "\n",
    "Labels = []\n",
    "labelData = pd.read_csv(Labels_Path)\n",
    "for i,j in zip(labelData['ClassId'] , labelData['SignName']) :\n",
    "    if i in ReqLabels :\n",
    "        Labels.append(j)\n",
    "        \n",
    "print(Labels)\n",
    "\n",
    "### 30 , 50 , 70 , 100 km/h and No entry , Stop , 19,20,27,33,34,35,36,37,38,39"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = pd.read_csv(Meta_Path)\n",
    "NoOfLabels = len(data['Path'])\n",
    "print(NoOfLabels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LoadData(Dir,typeLoad,count=100) :\n",
    "    data = pd.read_csv(Dir)\n",
    "    display(data.head())\n",
    "    X , Y = [] , []\n",
    "    for i,rx1,ry1,rx2,ry2,cId in zip(data['Path'],data['Roi.X1'],data['Roi.Y1'],data['Roi.X2'],data['Roi.Y2'],data['ClassId']) :\n",
    "        if cId in ReqLabels :\n",
    "            print(f'\\r{len(X)}\\t\\t',end=\"\")\n",
    "            i = 'D:/Data/Traffic Signs/' + i\n",
    "            img = cv2.imread(i)\n",
    "            img = img[ry1:ry2,rx1:rx2]\n",
    "            img = cv2.resize(img,(size,size))\n",
    "            if Count_Labels[cId] <= count-1 :\n",
    "                X.append(img)\n",
    "                Y.append(ReqLabels.index(cId))\n",
    "                if typeLoad == 'Train' or typeLoad == 'Test' :\n",
    "                    Count_Labels[cId] += 1\n",
    "        \n",
    "    return np.array(X)/255. , np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Loding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train , Y_train = LoadData(Train_Path,'Train',500)\n",
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Loading"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "X_test , Y_test = LoadData(Test_Path,'Test',100)\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'LoadedData.obj'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data = (X_train , X_test ,Y_train , Y_test)\n",
    "f = open(loc , 'wb')\n",
    "pickle.dump(Data , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(loc , 'rb')\n",
    "X_train , X_test ,Y_train , Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Model_Batch_1.0.obj'\n",
    "def callback(obj,fileName) :\n",
    "    print('CallBack : ',fileName,'Updated')\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'ReLU'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.input_shape=X.shape\n",
    "        self.output = np.maximum(0,X)\n",
    "        self.output_shape = self.input_shape\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        grad = Z > 0\n",
    "        #print(grad.shape,grad_output.shape)\n",
    "        return grad_output*grad\n",
    "    \n",
    "class TanH :\n",
    "    def __init__(self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'TanH'\n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.input_shape = X.shape\n",
    "        self.output = (np.exp(X)-np.exp(-X))/(np.exp(X)+np.exp(-X))\n",
    "        self.output_shape = self.output.shape\n",
    "        return self.output\n",
    "        \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        return 1-np.power(self.output,2)\n",
    "        \n",
    "class Softmax :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Softmax'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        #e_x = np.exp(X-np.max(X))\n",
    "        self.output = np.exp(X)/np.sum(np.exp(X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        e_x = np.exp(X)\n",
    "        return (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        e_x = np.exp(Z)\n",
    "        out = e_x/ex.sum()\n",
    "        grad = (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "        #grad = e_x/e_x.sum()**2 - (e_x**2/(e_x.sum()**2))\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Sigmoid :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Sigmoid'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.output = 1/(1+np.exp(-X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        out = 1/(1+np.exp(-X))\n",
    "        return out*(1-out)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        out = 1/(1+np.exp(-Z))\n",
    "        grad = out*((1-out)**2)\n",
    "        return grad_output*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten :\n",
    "    \n",
    "    \"\"\"\n",
    "        Flatten class is used to convert data into single dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,input_shape=None,output_shape=None,__Name__='Flatten') : ### Constructor called when we create object \n",
    "        self.__Name__ = __Name__ ### Defining __Name__ variable with Flatten\n",
    "        self.__type__ = 'flat' ### Defining __type__ variable\n",
    "        self.input_shape = input_shape\n",
    "        self.A_F = None\n",
    "        re = 1\n",
    "        if output_shape is None :\n",
    "            for i in input_shape :\n",
    "                re *= i\n",
    "            self.output_shape = re\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        \n",
    "    def feed(self,X) : ### feed function is used to transforms data into single dimension\n",
    "        #self.input = X\n",
    "        self.output = X.ravel() ### ravel is used to convert data into single dimensoin or flattens data\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,X,output_error) :\n",
    "        return X.reshape(self.input_shape)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense :\n",
    "    \n",
    "    def __init__ (self,input_shape,N_F,A_F=None,wt=None,bias=None,output_shape=None,__Name__='Dense') :\n",
    "        \n",
    "        \"\"\"\n",
    "            Wt and Bias range [-2.4/No of nodes , 2.4/No of nodes] Proposed by range\n",
    "        \"\"\"\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'dense'\n",
    "        self.input_shape = input_shape\n",
    "        self.N_F = N_F\n",
    "        self.A_F = A_F\n",
    "        if output_shape is None :\n",
    "            self.output_shape = N_F\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        if wt is None :\n",
    "            self.weights = np.random.uniform(-2.4/self.N_F,2.4/self.N_F,(self.input_shape, self.output_shape))\n",
    "        else :\n",
    "            self.weights = wt\n",
    "        if bias is None :\n",
    "            self.bias = np.random.uniform(-2.4/ self.N_F,2.4/ self.N_F,(1, self.output_shape))\n",
    "            #self.bias = np.zeros((1, self.output_shape))\n",
    "        else :\n",
    "            self.bias = bias\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        self.v_ = np.zeros((self.input_shape, self.output_shape))\n",
    "        self.s_ = np.zeros((self.input_shape, self.output_shape))\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        if X.shape[0] != 1 :\n",
    "            output = []\n",
    "            output.append(X)\n",
    "            self.input = np.array(output)\n",
    "        else :\n",
    "            self.input = X\n",
    "        self.output = np.matmul(X,self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def feed_back(self, Z , output_error, learning_rate=[1e-03],decay=1e-01,opt='sgd'):\n",
    "        input_error = np.dot(output_error,self.weights.T)\n",
    "        #output_error = output_error.mean(axis=0)*Z.T.shape[0]\n",
    "        weights , bias = None , None\n",
    "        weights_error = np.dot(Z.T, output_error)\n",
    "        input_error = np.dot(input_error.T,output_error)\n",
    "        lr = learning_rate[np.random.randint(len(learning_rate))]\n",
    "        #print(output_error.shape,input_error.shape,Neww.shape,weights_error.shape)\n",
    "        if opt.lower() == 'gd' :\n",
    "                weights = self.weights - lr * weights_error\n",
    "                bias = self.bias - lr * output_error\n",
    "        elif opt.lower() == 'sgd' :\n",
    "                weights = self.weights - lr * weights_error - lr * (decay/self.N_F) * input_error\n",
    "                bias = self.bias - lr * (decay/self.N_F) * output_error\n",
    "        elif opt.lower() == 'rmsprop' :\n",
    "                self.v_ = decay * self.v_ - lr * weights_error\n",
    "                weights = self.weights - self.v_ #- learning_rate * weights_error\n",
    "                bias = self.bias - lr * output_error\n",
    "        elif opt.lower() == 'adam' :\n",
    "                b1=.9\n",
    "                b2=.99\n",
    "                self.v_ = b1 * self.v_ - (1-b1) * weights_error\n",
    "                self.s_ = b2 * self.s_ - (1-b2) * np.power(weights_error , 2)\n",
    "                #print(self.s_ + decay)\n",
    "                weights = self.weights - lr * (self.v_ / np.sqrt(self.s_ + decay)) * weights_error\n",
    "                bias = self.bias - lr * output_error\n",
    "        return (weights , bias , input_error)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotAcc(model) : ### Accuracy Plot\n",
    "    plt.plot(range(model.ep),model.acc,c='r',label='acc')\n",
    "    plt.plot(range(model.ep),model.val_acc,c='b',label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def PlotError(model) : ### Error Plot\n",
    "    plt.plot(range(model.ep),model.error,c='black',label='error')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential :\n",
    "    \n",
    "    \"\"\"\n",
    "        Sequential is a class which is used to stack layers of model and to fit , predict , predicting classes of our given i/p\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self) :\n",
    "        self.Layers = []\n",
    "        self.input_shape = None\n",
    "        self.Activations = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.error = []\n",
    "        self.val_error = []\n",
    "        self.id = 1\n",
    "        self.ep = 1\n",
    "        \n",
    "    def add(self,Layer) :\n",
    "        boo = False\n",
    "        for layer in self.Layers :\n",
    "            if Layer.__type__ == layer.__type__ :\n",
    "                boo = True\n",
    "                if '_' not in Layer.__Name__ :\n",
    "                    Layer.__Name__ += '_'+str(self.id)\n",
    "                name,k = Layer.__Name__.split('_')\n",
    "                Layer.__Name__ = name+'_'+str(int(k)+1)\n",
    "        if not boo :\n",
    "            if '_' not in Layer.__Name__ :\n",
    "                Layer.__Name__ += '_'+str(self.id)\n",
    "        \n",
    "        self.Layers.append(Layer)\n",
    "        if Layer.__type__ != 'activation' :\n",
    "            if self.input_shape is None :\n",
    "                self.input_shape = Layer.input_shape\n",
    "            self.output_shape = Layer.output_shape\n",
    "        if Layer.A_F is not None :\n",
    "            if Layer.A_F.lower() == 'softmax' :\n",
    "                self.Activations.append(Softmax())\n",
    "            elif Layer.A_F.lower() == 'sigmoid' :\n",
    "                self.Activations.append(Sigmoid())\n",
    "            elif Layer.A_F.lower() == 'tanh' :\n",
    "                self.Activations.append(TanH())\n",
    "            else :\n",
    "                self.Activations.append(ReLU())\n",
    "        else :\n",
    "            self.Activations.append(None)\n",
    "    def ShuffleData(self,X,Y) :\n",
    "        order = np.random.randint(len(Y))\n",
    "        for i in range(len(Y)-1) :\n",
    "            X[order[i]] , X[order[i+1]] = X[order[i+1]] , X[order[i]]\n",
    "            Y[order[i]] , Y[order[i+1]] = Y[order[i+1]] , Y[order[i]]\n",
    "        return (X , Y)\n",
    "    \n",
    "    def SplitData(self,X,Y,split) :\n",
    "        input_data , output_data , val_input_data , val_output_data = None , None , None , None\n",
    "        N = int(len(Y) * (1-split))\n",
    "        while True :\n",
    "            X , Y = self.ShuffleData(X,Y)\n",
    "            if set(Y[:N]) != set(Y[N:]) :\n",
    "                X ,Y = self.ShuffleData(X,Y)\n",
    "            else :\n",
    "                input_data , output_data = X[:N] , Y[:N]\n",
    "                val_input_data , val_output_data = X[N:] , Y[N:]\n",
    "                break\n",
    "        return (input_data , output_data , val_input_data , val_output_data)\n",
    "        \n",
    "    def compile(self,optimizer='sgd',loss='cross_entropy',metrics=['acc']) :\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def one_hot_encode(self,l) :\n",
    "        Labels = np.zeros(self.Layers[-1].output_shape)\n",
    "        Labels[l] = 1\n",
    "#         for i,label in enumerate(labels) :\n",
    "#             Labels[i][label] = 1\n",
    "        return Labels\n",
    "\n",
    "    def trainModel(self , b , X , Y , lr,decay) : ### X and Y -> batch size of x and batch size of y and training model batch wise\n",
    "        c = 0\n",
    "        error = None\n",
    "        for x,y in zip(X,Y) :\n",
    "            # Training model\n",
    "            output = x\n",
    "            loss = None\n",
    "            \n",
    "            \"\"\"\n",
    "                Forward Feeding\n",
    "            \"\"\"\n",
    "            \n",
    "            #print(self.Layers , self.Activations)\n",
    "            \n",
    "            L_INPUTS , L_OUTPUTS , A_INPUTS , A_OUTPUTS = [] , [] , [] , []\n",
    "            \n",
    "            for layer , activation in zip(self.Layers , self.Activations) :\n",
    "                L_INPUTS.append(output)\n",
    "                output = layer.feed(output)\n",
    "                L_OUTPUTS.append(output)\n",
    "                if activation is not None :\n",
    "                    A_INPUTS.append(output)\n",
    "                    output = activation.feed(output)\n",
    "                    A_OUTPUTS.append(output)\n",
    "            \n",
    "            \"\"\"\n",
    "                Loss Calculation\n",
    "            \"\"\"\n",
    "            \n",
    "            if self.loss == 'cross_entropy' :\n",
    "                loss = self.cat_crossentropy(A_OUTPUTS[-1],Y)\n",
    "                if math.isnan(loss) :\n",
    "                    return None\n",
    "                grad_activation = self.Activations[-1].grad_feed(L_OUTPUTS[-1])\n",
    "                out_err = self.grad_crossentropy(L_OUTPUTS[-1],Y)*grad_activation\n",
    "            \n",
    "            \"\"\"\n",
    "                Backward Feeding\n",
    "            \"\"\"\n",
    "            try :\n",
    "                for i in range(1,len(self.Layers)-1) :\n",
    "                    if self.Layers[-i].__Name__[0] != 'F' :\n",
    "                        if self.Activations[-i].__Name__ != 'Softmax' :\n",
    "                            out_err = self.Activations[-i].feed_back(A_INPUTS[-i],out_err,lr)\n",
    "                        w , b_ , out_err = self.Layers[-i].feed_back(L_INPUTS[-i],out_err,lr,decay,opt=self.optimizer)\n",
    "                        self.Layers[-i].Batch_W.append(w)\n",
    "                        self.Layers[-i].Batch_B.append(b_)\n",
    "                    else :\n",
    "                        break\n",
    "            except Exception as e :\n",
    "                    print(e)\n",
    "                    pass\n",
    "                \n",
    "            error = np.mean(loss)\n",
    "            c += 1\n",
    "            #print('\\rbatch = %d , c = %d , error=%f' % (b,c,error),end=\"\")\n",
    "            print('\\r Loss : %f ' % (error) , end=\"\")\n",
    "            \n",
    "        for i in range(1,len(self.Layers)-1) :\n",
    "            if self.Layers[-i].__Name__[0] != 'F' :\n",
    "                Batch_W = np.array(self.Layers[-i].Batch_W)\n",
    "                Batch_B = np.array(self.Layers[-i].Batch_B)\n",
    "                self.Layers[-i].weights = np.mean(self.Layers[-i].Batch_W , axis = 0)\n",
    "                self.Layers[-i].bias = np.mean(self.Layers[-i].Batch_B)\n",
    "                self.Layers[-i].Batch_W = []\n",
    "                self.Layers[-i].Batch_B = []\n",
    "                \n",
    "        return error\n",
    "            \n",
    "    def fit(self,train_data,valid_data=None,validation_split=.2,epochs=10,lr=1e-02,decay=1e-03,batch_size=8,model_updation_epoch=2,PlotView=10) :\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        input_data , output_data = None , None\n",
    "        val_input_data , val_target_data = None , None\n",
    "        if train_data is None :\n",
    "            raise ValueError('Training Data Required')\n",
    "        else :\n",
    "            input_data = train_data[0]\n",
    "            output_data = train_data[1]\n",
    "        N = len(input_data)\n",
    "        \n",
    "        if valid_data is None :\n",
    "            input_data , output_data , val_input_data , val_output_data = self.SplitData(input_data , output_data , validation_split)\n",
    "        else :\n",
    "            val_input_data , val_target_data = valid_data[0] , valid_data[1]\n",
    "        print('\\nModel Fitting\\n')\n",
    "        \n",
    "        N = len(output_data)\n",
    "#         input_data = normalize(input_data,axis=0)\n",
    "#         val_input_data = normalize(val_input_data,axis=0)\n",
    "        for ep in range(epochs) :\n",
    "            model.ep = ep + 1\n",
    "            start_ep = time.time()\n",
    "            error = 0\n",
    "            acc = 0\n",
    "            print(f'\\nepoch : {ep+1}/{epochs}')\n",
    "            \n",
    "            for b,batch in enumerate(tnrange(0,N-batch_size+1,batch_size,desc='batch')) :\n",
    "                #print(b,batch)\n",
    "                X , Y = input_data[batch:batch+batch_size] , output_data[batch : batch+batch_size]\n",
    "                error = self.trainModel(b , X , Y , lr , decay)\n",
    "                while error is None :\n",
    "                    model.ep = ep - 1\n",
    "                    #error = self.trainModel(b , X , Y , lr)\n",
    "                    callback(model,fileName)\n",
    "                    loop_break = True\n",
    "                    return self\n",
    "            \n",
    "            ### Accuracy , Val_Accuracy , Loss , Val_loss\n",
    "#             if loop_break :\n",
    "#                 break\n",
    "            accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(input_data, output_data)]) / N\n",
    "            self.acc.append(accuracy)\n",
    "            self.error.append(error)\n",
    "            \n",
    "            if 'acc' in self.metrics :\n",
    "                val_accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(val_input_data, val_target_data)]) / len(val_input_data)\n",
    "                self.val_acc.append(val_accuracy)\n",
    "                print(' acc=%f , val_acc=%f' % (accuracy , val_accuracy))\n",
    "            else :\n",
    "                print('\\racc=%f' % (accuracy))\n",
    "            callback(model,fileName)\n",
    "            \n",
    "            if not (ep+1)%PlotView :\n",
    "                PlotAcc(self)\n",
    "                PlotError(self)\n",
    "            \n",
    "            #end_ep = time.time()\n",
    "            \n",
    "            #print(f'Time Taken for epoch {ep+1} : {end_ep-start_ep}s')\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "    \n",
    "    def mse_prime(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_pred.size\n",
    "    \n",
    "    def transfer_derivative(self,output):\n",
    "        return output * (1.0 - output)\n",
    "    \n",
    "    def binary_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -np.mean(GroundTruth*np.log(pred)+(1-GroundTruth)*np.log(1-pred))\n",
    "    \n",
    "    def binary_grad_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -((GroundTruth/pred)-((1-GroundTruth)/(1-pred)))\n",
    "    \n",
    "    def cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "#         a = Truth/pred\n",
    "#         b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "#         print(Truth,pred,a,b)\n",
    "#         print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "\n",
    "    def grad_cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        a = Truth/pred\n",
    "        b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "        print(Truth,pred,a,b)\n",
    "        print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "    \n",
    "    def crossentropy(self,logits,reference_answers):\n",
    "        return - logits[0][reference_answers] + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    def grad_crossentropy(self,logits,reference_answers):\n",
    "        ones_for_answers = np.zeros_like(logits)\n",
    "        ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "        softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "    \n",
    "    def showImg(self,X) :\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        outputs = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = X\n",
    "            for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                output = layer.feed(output)\n",
    "                if activation is not None :\n",
    "                    output = activation.feed(output)\n",
    "            outputs.append(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    output = layer.feed(output)\n",
    "                    if activation is not None :\n",
    "                        output = activation.feed(output)\n",
    "                outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def pred_class(self,X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = self.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = self.predict(output)\n",
    "                classes.append(np.argmax(output))\n",
    "            return np.array(classes)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        print('='*60)\n",
    "        print('Model Summary')\n",
    "        print('_'*60)\n",
    "        print('Layers',' '*(20-len('Layers')),'Input Shape',' '*(20-len('Input Shape')),'Output Shape',' '*(20-len('Output Shape')))\n",
    "        print('='*60)\n",
    "        for Layer in self.Layers :\n",
    "            if Layer.__type__ != 'activation' :\n",
    "                Layer.Summary()\n",
    "                print('_'*60)\n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=100,A_F='ReLU')) ### Input Layer\n",
    "#model.add(Dense(input_shape=model.output_shape,N_F=32,A_F='ReLU')) ## Hidden Layer\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=len(set(Y_train)),A_F='Softmax')) ### Output Layer\n",
    "model.compile(optimizer='sgd',loss='cross_entropy',metrics=['acc'])\n",
    "\n",
    "model.Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data=(X_train,Y_train),\n",
    "          valid_data=(X_test,Y_test),\n",
    "          epochs=epochs,\n",
    "          lr=[1e-01,1e-01*2,1e-0*3,1e-01*4,1e-01*5],\n",
    "          decay=1e-01*3,\n",
    "          batch_size=32,\n",
    "          PlotView=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(obj,fileName) :\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)\n",
    "    \n",
    "def loadModel(fileName) :\n",
    "    f = open(fileName, 'rb') \n",
    "    model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAcc(model)\n",
    "PlotError(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.pred_class(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pred_class(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(X_train)) :\n",
    "    #print(model.pred_class(X_train[i]),Y_train[i])\n",
    "    if model.pred_class(X_train[i]) == Y_train[i] :\n",
    "        c += 1\n",
    "print(c*100/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[1]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[100]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
