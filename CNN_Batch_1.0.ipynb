{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (30km/h)', 'Speed limit (60km/h)', 'Speed limit (80km/h)', 'Speed limit (100km/h)', 'Stop', 'No entry', 'Dangerous curve to the left', 'Dangerous curve to the right', 'Traffic signals', 'Turn right ahead', 'Turn left ahead', 'Go straight or right', 'Go straight or left', 'Keep right', 'Keep left']\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "size = 100\n",
    "#ReqLabels = [1,3,5,7,14]#,17,19,20,26,33,34,36,37,38,39]\n",
    "ReqLabels = [1,3,5,7,14,17,19,20,26,33,34,36,37,38,39]\n",
    "#ReqLabels = [1,14,38,39]\n",
    "Train_Path = 'D:/Data/Traffic Signs/Train.csv'\n",
    "Test_Path = 'D:/Data/Traffic Signs/Test.csv'\n",
    "Meta_Path = 'D:/Data/Traffic Signs/Meta.csv'\n",
    "Labels_Path = 'D:/Data/Traffic Signs/Labels.csv'\n",
    "\n",
    "Labels = []\n",
    "labelData = pd.read_csv(Labels_Path)\n",
    "for i,j in zip(labelData['ClassId'] , labelData['SignName']) :\n",
    "    if i in ReqLabels :\n",
    "        Labels.append(j)\n",
    "        \n",
    "print(Labels)\n",
    "\n",
    "### 30 , 50 , 70 , 100 km/h and No entry , Stop , 19,20,27,33,34,35,36,37,38,39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(Meta_Path)\n",
    "NoOfLabels = len(data['Path'])\n",
    "print(NoOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 3: 0,\n",
       " 5: 0,\n",
       " 7: 0,\n",
       " 14: 0,\n",
       " 17: 0,\n",
       " 19: 0,\n",
       " 20: 0,\n",
       " 26: 0,\n",
       " 33: 0,\n",
       " 34: 0,\n",
       " 36: 0,\n",
       " 37: 0,\n",
       " 38: 0,\n",
       " 39: 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(Dir,typeLoad,count=100) :\n",
    "    data = pd.read_csv(Dir)\n",
    "    display(data.head())\n",
    "    X , Y = [] , []\n",
    "    for i,rx1,ry1,rx2,ry2,cId in zip(data['Path'],data['Roi.X1'],data['Roi.Y1'],data['Roi.X2'],data['Roi.Y2'],data['ClassId']) :\n",
    "        if cId in ReqLabels :\n",
    "            print(f'\\r{len(X)}\\t\\t',end=\"\")\n",
    "            i = 'D:/Data/Traffic Signs/' + i\n",
    "            img = cv2.imread(i)\n",
    "            img = img[ry1:ry2,rx1:rx2]\n",
    "            img = cv2.resize(img,(size,size))\n",
    "            if Count_Labels[cId] <= count-1 :\n",
    "                X.append(img)\n",
    "                Y.append(ReqLabels.index(cId))\n",
    "                if typeLoad == 'Train' or typeLoad == 'Test' :\n",
    "                    Count_Labels[cId] += 1\n",
    "        \n",
    "    return np.array(X)/255. , np.array(Y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train , Y_train = LoadData(Train_Path,'Train',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_test , Y_test = LoadData(Test_Path,'Test',60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'LoadedData.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = (X_train , X_test ,Y_train , Y_test)\n",
    "f = open(loc , 'wb')\n",
    "pickle.dump(Data , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(loc , 'rb')\n",
    "X_train , X_test ,Y_train , Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Model_Batch_1.0.obj'\n",
    "def callback(obj,fileName) :\n",
    "    print('CallBack : ',fileName,'Updated')\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'ReLU'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.input_shape=X.shape\n",
    "        self.output = np.maximum(0,X)\n",
    "        self.output_shape = self.input_shape\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        grad = Z > 0\n",
    "        #print(grad.shape,grad_output.shape)\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Softmax :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Softmax'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        #e_x = np.exp(X-np.max(X))\n",
    "        self.output = np.exp(X)/np.sum(np.exp(X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        e_x = np.exp(X)\n",
    "        return (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        e_x = np.exp(Z)\n",
    "        out = e_x/ex.sum()\n",
    "        grad = (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "        #grad = e_x/e_x.sum()**2 - (e_x**2/(e_x.sum()**2))\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Sigmoid :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Sigmoid'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.output = 1/(1+np.exp(-X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        out = 1/(1+np.exp(-X))\n",
    "        return out*(1-out)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        out = 1/(1+np.exp(-Z))\n",
    "        grad = out*((1-out)**2)\n",
    "        return grad_output*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten :\n",
    "    \n",
    "    \"\"\"\n",
    "        Flatten class is used to convert data into single dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,input_shape=None,output_shape=None,__Name__='Flatten') : ### Constructor called when we create object \n",
    "        self.__Name__ = __Name__ ### Defining __Name__ variable with Flatten\n",
    "        self.__type__ = 'flat' ### Defining __type__ variable\n",
    "        self.input_shape = input_shape\n",
    "        self.A_F = None\n",
    "        re = 1\n",
    "        if output_shape is None :\n",
    "            for i in input_shape :\n",
    "                re *= i\n",
    "            self.output_shape = re\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        \n",
    "    def feed(self,X) : ### feed function is used to transforms data into single dimension\n",
    "        #self.input = X\n",
    "        self.output = X.ravel() ### ravel is used to convert data into single dimensoin or flattens data\n",
    "        return self.output\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense :\n",
    "    \n",
    "    def __init__ (self,input_shape,N_F,A_F=None,wt=None,bias=None,output_shape=None,__Name__='Dense') :\n",
    "        \n",
    "        \"\"\"\n",
    "            Wt and Bias range [-2.4/No of nodes , 2.4/No of nodes] Proposed by range\n",
    "        \"\"\"\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'dense'\n",
    "        self.input_shape = input_shape\n",
    "        self.N_F = N_F\n",
    "        self.A_F = A_F\n",
    "        if output_shape is None :\n",
    "            self.output_shape = N_F\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        if wt is None :\n",
    "            self.weights = np.random.uniform(-2.4/self.N_F,2.4/self.N_F,(self.input_shape, self.output_shape))\n",
    "        else :\n",
    "            self.weights = wt\n",
    "        if bias is None :\n",
    "            self.bias = np.random.uniform(-2.4/ self.N_F,2.4/ self.N_F,(1, self.output_shape)) / self.N_F\n",
    "        else :\n",
    "            self.bias = bias\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        if X.shape[0] != 1 :\n",
    "            output = []\n",
    "            output.append(X)\n",
    "            self.input = np.array(output)\n",
    "        else :\n",
    "            self.input = X\n",
    "        self.output = np.matmul(X,self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "#     def feed_back(self, Z , output_error, learning_rate=1e-03,deacy=1e-02):\n",
    "#         input_error = np.dot(output_error, self.weights.T)\n",
    "#         #output_error = output_error.mean(axis=0)*Z.T.shape[0]\n",
    "#         weights_error = np.dot(Z.T, output_error)\n",
    "#         self.weights = self.weights - learning_rate * weights_error\n",
    "#         self.bias = self.bias - learning_rate * output_error\n",
    "# #         self.weights = (1-decay)*self.weights - learning_rate * weights_error\n",
    "# #         self.bias = (1-decay)*self.bias - learning_rate * output_error\n",
    "#         return input_error\n",
    "\n",
    "    def feed_back(self, Z , output_error, learning_rate=1e-03,deacy=1e-02):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        #output_error = output_error.mean(axis=0)*Z.T.shape[0]\n",
    "        weights_error = np.dot(Z.T, output_error)\n",
    "#         self.weights = self.weights - learning_rate * weights_error\n",
    "#         self.bias = self.bias - learning_rate * output_error\n",
    "        weights = self.weights - learning_rate * weights_error\n",
    "        bias = self.bias - learning_rate * output_error\n",
    "        return (weights , bias , input_error)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential :\n",
    "    \n",
    "    \"\"\"\n",
    "        Sequential is a class which is used to stack layers of model and to fit , predict , predicting classes of our given i/p\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self) :\n",
    "        self.Layers = []\n",
    "        self.input_shape = None\n",
    "        self.Activations = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.error = []\n",
    "        self.val_error = []\n",
    "        self.id = 1\n",
    "        \n",
    "    def add(self,Layer) :\n",
    "        boo = False\n",
    "        for layer in self.Layers :\n",
    "            if Layer.__type__ == layer.__type__ :\n",
    "                boo = True\n",
    "                if '_' not in Layer.__Name__ :\n",
    "                    Layer.__Name__ += '_'+str(self.id)\n",
    "                name,k = Layer.__Name__.split('_')\n",
    "                Layer.__Name__ = name+'_'+str(int(k)+1)\n",
    "        if not boo :\n",
    "            if '_' not in Layer.__Name__ :\n",
    "                Layer.__Name__ += '_'+str(self.id)\n",
    "        \n",
    "        self.Layers.append(Layer)\n",
    "        if Layer.__type__ != 'activation' :\n",
    "            if self.input_shape is None :\n",
    "                self.input_shape = Layer.input_shape\n",
    "            self.output_shape = Layer.output_shape\n",
    "        if Layer.A_F is not None :\n",
    "            if Layer.A_F.lower() == 'softmax' :\n",
    "                self.Activations.append(Softmax())\n",
    "            elif Layer.A_F.lower() == 'sigmoid' :\n",
    "                self.Activations.append(Sigmoid())\n",
    "            else :\n",
    "                self.Activations.append(ReLU())\n",
    "        else :\n",
    "            self.Activations.append(None)\n",
    "    def ShuffleData(self,X,Y) :\n",
    "        order = np.random.randint(len(Y))\n",
    "        for i in range(len(Y)-1) :\n",
    "            X[order[i]] , X[order[i+1]] = X[order[i+1]] , X[order[i]]\n",
    "            Y[order[i]] , Y[order[i+1]] = Y[order[i+1]] , Y[order[i]]\n",
    "        return (X , Y)\n",
    "    \n",
    "    def SplitData(self,X,Y,split) :\n",
    "        input_data , output_data , val_input_data , val_output_data = None , None , None , None\n",
    "        N = int(len(Y) * (1-split))\n",
    "        while True :\n",
    "            X , Y = self.ShuffleData(X,Y)\n",
    "            if set(Y[:N]) != set(Y[N:]) :\n",
    "                X ,Y = self.ShuffleData(X,Y)\n",
    "            else :\n",
    "                input_data , output_data = X[:N] , Y[:N]\n",
    "                val_input_data , val_output_data = X[N:] , Y[N:]\n",
    "                break\n",
    "        return (input_data , output_data , val_input_data , val_output_data)\n",
    "        \n",
    "    def compile(self,loss='cross_entropy',metrics=['acc']) :\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def one_hot_encode(self,l) :\n",
    "        Labels = np.zeros(self.Layers[-1].output_shape)\n",
    "        Labels[l] = 1\n",
    "#         for i,label in enumerate(labels) :\n",
    "#             Labels[i][label] = 1\n",
    "        return Labels\n",
    "\n",
    "    def trainModel(self , b , X , Y , lr) : ### X and Y -> batch size of x and batch size of y and training model batch wise\n",
    "        c = 0\n",
    "        error = None\n",
    "        for x,y in zip(X,Y) :\n",
    "            # Training model\n",
    "            output = x\n",
    "            loss = None\n",
    "            \n",
    "            \"\"\"\n",
    "                Forward Feeding\n",
    "            \"\"\"\n",
    "            \n",
    "            #print(self.Layers , self.Activations)\n",
    "            \n",
    "            L_INPUTS , L_OUTPUTS , A_INPUTS , A_OUTPUTS = [] , [] , [] , []\n",
    "            \n",
    "            for layer , activation in zip(self.Layers , self.Activations) :\n",
    "                L_INPUTS.append(output)\n",
    "                output = layer.feed(output)\n",
    "                L_OUTPUTS.append(output)\n",
    "                if activation is not None :\n",
    "                    A_INPUTS.append(output)\n",
    "                    output = activation.feed(output)\n",
    "                    A_OUTPUTS.append(output)\n",
    "            \n",
    "            \"\"\"\n",
    "                Loss Calculation\n",
    "            \"\"\"\n",
    "            \n",
    "            if self.loss == 'cross_entropy' :\n",
    "                loss = self.cat_crossentropy(A_OUTPUTS[-1],Y)\n",
    "                if math.isnan(loss) :\n",
    "                    model.epochs = ep-1\n",
    "                    return None\n",
    "                grad_activation = self.Activations[-1].grad_feed(L_OUTPUTS[-1])\n",
    "                out_err = self.grad_crossentropy(L_OUTPUTS[-1],Y)*grad_activation\n",
    "            \n",
    "            \"\"\"\n",
    "                Backward Feeding\n",
    "            \"\"\"\n",
    "            try :\n",
    "                for i in range(1,len(self.Layers)-1) :\n",
    "                    if self.Layers[-i].__Name__[0] != 'F' :\n",
    "                        if self.Activations[-i].__Name__ != 'Softmax' :\n",
    "                            out_err = self.Activations[-i].feed_back(A_INPUTS[-i],out_err,lr)\n",
    "                        w , b_ , out_err = self.Layers[-i].feed_back(L_INPUTS[-i],out_err,lr)\n",
    "                        self.Layers[-i].Batch_W.append(w)\n",
    "                        self.Layers[-i].Batch_B.append(b_)\n",
    "                    else :\n",
    "                            break\n",
    "            except Exception as e :\n",
    "                    print(e)\n",
    "                    pass\n",
    "                \n",
    "            error = np.mean(loss)\n",
    "            c += 1\n",
    "            print('\\rbatch = %d , c = %d , error=%f' % (b,c,error),end=\"\")\n",
    "            \n",
    "        for i in range(len(self.Layers)-1) :\n",
    "            if self.Layers[-i].__Name__[0] != 'F' :\n",
    "                Batch_W = np.array(self.Layers[-i].Batch_W)\n",
    "                self.Layers[-i].weights = np.mean(self.Layers[-i].Batch_W , axis = 0)\n",
    "                self.Layers[-i].bias = np.mean(self.Layers[-i].Batch_B)\n",
    "                self.Layers[-i].Batch_W = []\n",
    "                self.Layers[-i].Batch_B = []\n",
    "                \n",
    "        return error\n",
    "            \n",
    "    def fit(self,train_data,valid_data=None,validation_split=.2,epochs=10,lr=1e-02,decay=1e-03,batch_size=8) :\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        input_data , output_data = None , None\n",
    "        val_input_data , val_target_data = None , None\n",
    "        if train_data is None :\n",
    "            raise ValueError('Training Data Required')\n",
    "        else :\n",
    "            input_data = train_data[0]\n",
    "            output_data = train_data[1]\n",
    "        N = len(input_data)\n",
    "        \n",
    "        if valid_data is None :\n",
    "            input_data , output_data , val_input_data , val_output_data = self.SplitData(input_data , output_data , validation_split)\n",
    "        else :\n",
    "            val_input_data , val_target_data = valid_data[0] , valid_data[1]\n",
    "        print('\\nModel Fitting\\n')\n",
    "        \n",
    "        N = len(output_data)\n",
    "        for ep in range(epochs) :\n",
    "            start_ep = time.time()\n",
    "            error = 0\n",
    "            acc = 0\n",
    "            print(f'\\nepoch : {ep+1}/{epochs}')\n",
    "            \n",
    "            for b,batch in enumerate(range(0,N-batch_size+1,batch_size)) :\n",
    "                #print(b,batch)\n",
    "                X , Y = input_data[batch:batch+batch_size] , output_data[batch : batch+batch_size]\n",
    "                error = self.trainModel(b , X , Y , lr)\n",
    "            \n",
    "            ### Accuracy , Val_Accuracy , Loss , Val_loss\n",
    "            \n",
    "            accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(input_data, output_data)]) / len(input_data)\n",
    "            self.acc.append(accuracy)\n",
    "            self.error.append(error)\n",
    "            \n",
    "            if 'acc' in self.metrics :\n",
    "                val_accuracy = sum([y == np.argmax(model.predict(x)) for x, y in zip(val_input_data, val_target_data)]) / len(val_input_data)\n",
    "                self.val_acc.append(val_accuracy)\n",
    "                print(' acc=%f , val_acc=%f' % (accuracy , val_accuracy))\n",
    "            else :\n",
    "                print('\\racc=%f' % (accuracy))\n",
    "                \n",
    "            callback(model,fileName)\n",
    "            \n",
    "            end_ep = time.time()\n",
    "            \n",
    "            print(f'Time Taken for epoch {ep+1} : {end_ep-start_ep}s')\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "    \n",
    "    def mse_prime(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_pred.size\n",
    "    \n",
    "    def transfer_derivative(self,output):\n",
    "        return output * (1.0 - output)\n",
    "    \n",
    "    def binary_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -np.mean(GroundTruth*np.log(pred)+(1-GroundTruth)*np.log(1-pred))\n",
    "    \n",
    "    def binary_grad_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -((GroundTruth/pred)-((1-GroundTruth)/(1-pred)))\n",
    "    \n",
    "    def cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "#         a = Truth/pred\n",
    "#         b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "#         print(Truth,pred,a,b)\n",
    "#         print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "\n",
    "    def grad_cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        a = Truth/pred\n",
    "        b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "        print(Truth,pred,a,b)\n",
    "        print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "    \n",
    "    def crossentropy(self,logits,reference_answers):\n",
    "        return - logits[0][reference_answers] + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    def grad_crossentropy(self,logits,reference_answers):\n",
    "        ones_for_answers = np.zeros_like(logits)\n",
    "        ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "        softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "    \n",
    "    def showImg(self,X) :\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        outputs = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = X\n",
    "            for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                output = layer.feed(output)\n",
    "                if activation is not None :\n",
    "                    output = activation.feed(output)\n",
    "            outputs.append(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    output = layer.feed(output)\n",
    "                    if activation is not None :\n",
    "                        output = activation.feed(output)\n",
    "                outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def pred_class(self,X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = self.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = self.predict(output)\n",
    "                classes.append(np.argmax(output))\n",
    "            return np.array(classes)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        print('='*60)\n",
    "        print('Model Summary')\n",
    "        print('_'*60)\n",
    "        print('Layers',' '*(20-len('Layers')),'Input Shape',' '*(20-len('Input Shape')),'Output Shape',' '*(20-len('Output Shape')))\n",
    "        print('='*60)\n",
    "        for Layer in self.Layers :\n",
    "            if Layer.__type__ != 'activation' :\n",
    "                Layer.Summary()\n",
    "                print('_'*60)\n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model Summary\n",
      "____________________________________________________________\n",
      "Layers                Input Shape           Output Shape         \n",
      "============================================================\n",
      "Flatten_1             (100, 100, 3)         30000\n",
      "____________________________________________________________\n",
      "Dense_1               30000                 100\n",
      "____________________________________________________________\n",
      "Dense_2               100                   15\n",
      "____________________________________________________________\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=100,A_F='ReLU')) ### Input Layer\n",
    "#model.add(Dense(input_shape=model.output_shape,N_F=32,A_F='ReLU')) ## Hidden Layer\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=len(set(Y_train)),A_F='Softmax')) ### Output Layer\n",
    "model.compile(loss='cross_entropy',metrics=['acc'])\n",
    "\n",
    "model.Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fitting\n",
      "\n",
      "\n",
      "epoch : 1/200\n",
      "batch = 92 , c = 32 , error=0.915642 acc=0.112000 , val_acc=0.086667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 1 : 15.303024768829346s\n",
      "\n",
      "epoch : 2/200\n",
      "batch = 92 , c = 32 , error=0.907862 acc=0.119333 , val_acc=0.091111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 2 : 14.763090372085571s\n",
      "\n",
      "epoch : 3/200\n",
      "batch = 92 , c = 32 , error=0.901170 acc=0.133667 , val_acc=0.093333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 3 : 14.219900608062744s\n",
      "\n",
      "epoch : 4/200\n",
      "batch = 92 , c = 32 , error=0.893149 acc=0.143667 , val_acc=0.103333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 4 : 14.375239372253418s\n",
      "\n",
      "epoch : 5/200\n",
      "batch = 92 , c = 32 , error=0.884086 acc=0.166000 , val_acc=0.116667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 5 : 14.110788583755493s\n",
      "\n",
      "epoch : 6/200\n",
      "batch = 92 , c = 32 , error=0.874883 acc=0.192667 , val_acc=0.154444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 6 : 14.273102760314941s\n",
      "\n",
      "epoch : 7/200\n",
      "batch = 92 , c = 32 , error=0.866587 acc=0.209000 , val_acc=0.170000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 7 : 16.77714228630066s\n",
      "\n",
      "epoch : 8/200\n",
      "batch = 92 , c = 32 , error=0.859724 acc=0.224000 , val_acc=0.183333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 8 : 16.36642861366272s\n",
      "\n",
      "epoch : 9/200\n",
      "batch = 92 , c = 32 , error=0.854153 acc=0.237000 , val_acc=0.201111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 9 : 20.027146577835083s\n",
      "\n",
      "epoch : 10/200\n",
      "batch = 92 , c = 32 , error=0.849420 acc=0.249333 , val_acc=0.216667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 10 : 17.690101385116577s\n",
      "\n",
      "epoch : 11/200\n",
      "batch = 92 , c = 32 , error=0.845083 acc=0.266333 , val_acc=0.233333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 11 : 19.700918436050415s\n",
      "\n",
      "epoch : 12/200\n",
      "batch = 92 , c = 32 , error=0.840862 acc=0.286000 , val_acc=0.253333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 12 : 17.317291975021362s\n",
      "\n",
      "epoch : 13/200\n",
      "batch = 92 , c = 32 , error=0.836621 acc=0.307667 , val_acc=0.276667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 13 : 17.16447401046753s\n",
      "\n",
      "epoch : 14/200\n",
      "batch = 92 , c = 32 , error=0.832295 acc=0.332000 , val_acc=0.300000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 14 : 17.443992137908936s\n",
      "\n",
      "epoch : 15/200\n",
      "batch = 92 , c = 32 , error=0.827847 acc=0.355000 , val_acc=0.317778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 15 : 22.712846040725708s\n",
      "\n",
      "epoch : 16/200\n",
      "batch = 92 , c = 32 , error=0.823265 acc=0.377667 , val_acc=0.328889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 16 : 18.524672269821167s\n",
      "\n",
      "epoch : 17/200\n",
      "batch = 92 , c = 32 , error=0.818550 acc=0.396333 , val_acc=0.345556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 17 : 20.44304347038269s\n",
      "\n",
      "epoch : 18/200\n",
      "batch = 92 , c = 32 , error=0.813715 acc=0.413333 , val_acc=0.352222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 18 : 18.50906252861023s\n",
      "\n",
      "epoch : 19/200\n",
      "batch = 92 , c = 32 , error=0.808779 acc=0.431667 , val_acc=0.362222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 19 : 18.629384517669678s\n",
      "\n",
      "epoch : 20/200\n",
      "batch = 92 , c = 32 , error=0.803765 acc=0.447667 , val_acc=0.371111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 20 : 19.568825006484985s\n",
      "\n",
      "epoch : 21/200\n",
      "batch = 92 , c = 32 , error=0.798696 acc=0.462000 , val_acc=0.377778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 21 : 17.294760704040527s\n",
      "\n",
      "epoch : 22/200\n",
      "batch = 92 , c = 32 , error=0.793596 acc=0.475667 , val_acc=0.377778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 22 : 19.295296907424927s\n",
      "\n",
      "epoch : 23/200\n",
      "batch = 92 , c = 32 , error=0.788487 acc=0.484333 , val_acc=0.376667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 23 : 19.273552417755127s\n",
      "\n",
      "epoch : 24/200\n",
      "batch = 92 , c = 32 , error=0.783389 acc=0.493000 , val_acc=0.386667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 24 : 18.243916273117065s\n",
      "\n",
      "epoch : 25/200\n",
      "batch = 92 , c = 32 , error=0.778325 acc=0.504667 , val_acc=0.394444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 25 : 14.930654048919678s\n",
      "\n",
      "epoch : 26/200\n",
      "batch = 92 , c = 32 , error=0.773319 acc=0.513000 , val_acc=0.408889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 26 : 14.285799264907837s\n",
      "\n",
      "epoch : 27/200\n",
      "batch = 92 , c = 32 , error=0.768393 acc=0.522333 , val_acc=0.420000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 27 : 13.437472105026245s\n",
      "\n",
      "epoch : 28/200\n",
      "batch = 92 , c = 32 , error=0.763568 acc=0.527667 , val_acc=0.431111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 28 : 13.139747381210327s\n",
      "\n",
      "epoch : 29/200\n",
      "batch = 92 , c = 32 , error=0.758861 acc=0.532667 , val_acc=0.440000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 29 : 13.179100036621094s\n",
      "\n",
      "epoch : 30/200\n",
      "batch = 92 , c = 32 , error=0.754283 acc=0.535333 , val_acc=0.444444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 30 : 13.038577556610107s\n",
      "\n",
      "epoch : 31/200\n",
      "batch = 92 , c = 32 , error=0.749840 acc=0.537333 , val_acc=0.450000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 31 : 13.363778114318848s\n",
      "\n",
      "epoch : 32/200\n",
      "batch = 92 , c = 32 , error=0.745533 acc=0.540000 , val_acc=0.452222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 32 : 13.32948112487793s\n",
      "\n",
      "epoch : 33/200\n",
      "batch = 92 , c = 32 , error=0.741361 acc=0.541000 , val_acc=0.456667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 33 : 13.449054718017578s\n",
      "\n",
      "epoch : 34/200\n",
      "batch = 92 , c = 32 , error=0.737318 acc=0.545333 , val_acc=0.463333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 34 : 13.266913175582886s\n",
      "\n",
      "epoch : 35/200\n",
      "batch = 92 , c = 32 , error=0.733397 acc=0.546000 , val_acc=0.475556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 35 : 13.342288732528687s\n",
      "\n",
      "epoch : 36/200\n",
      "batch = 92 , c = 32 , error=0.729589 acc=0.547000 , val_acc=0.484444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 36 : 13.291768074035645s\n",
      "\n",
      "epoch : 37/200\n",
      "batch = 92 , c = 32 , error=0.725887 acc=0.549333 , val_acc=0.494444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 37 : 13.377639293670654s\n",
      "\n",
      "epoch : 38/200\n",
      "batch = 92 , c = 32 , error=0.722280 acc=0.550000 , val_acc=0.498889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 38 : 13.289599895477295s\n",
      "\n",
      "epoch : 39/200\n",
      "batch = 92 , c = 32 , error=0.718760 acc=0.552667 , val_acc=0.498889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 39 : 13.373380422592163s\n",
      "\n",
      "epoch : 40/200\n",
      "batch = 92 , c = 32 , error=0.715322 acc=0.553333 , val_acc=0.501111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 40 : 13.220376014709473s\n",
      "\n",
      "epoch : 41/200\n",
      "batch = 92 , c = 32 , error=0.711958 acc=0.553333 , val_acc=0.504444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 41 : 13.227962493896484s\n",
      "\n",
      "epoch : 42/200\n",
      "batch = 92 , c = 32 , error=0.708666 acc=0.555667 , val_acc=0.510000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 42 : 13.459820747375488s\n",
      "\n",
      "epoch : 43/200\n",
      "batch = 92 , c = 32 , error=0.705443 acc=0.555667 , val_acc=0.513333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 43 : 13.240810871124268s\n",
      "\n",
      "epoch : 44/200\n",
      "batch = 92 , c = 32 , error=0.702287 acc=0.557667 , val_acc=0.518889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 44 : 13.564469814300537s\n",
      "\n",
      "epoch : 45/200\n",
      "batch = 92 , c = 32 , error=0.699197 acc=0.561000 , val_acc=0.523333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 45 : 13.34483814239502s\n",
      "\n",
      "epoch : 46/200\n",
      "batch = 92 , c = 32 , error=0.696174 acc=0.563333 , val_acc=0.524444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 46 : 13.252887487411499s\n",
      "\n",
      "epoch : 47/200\n",
      "batch = 92 , c = 32 , error=0.693217 acc=0.565000 , val_acc=0.526667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 47 : 13.139010190963745s\n",
      "\n",
      "epoch : 48/200\n",
      "batch = 92 , c = 32 , error=0.690326 acc=0.567000 , val_acc=0.526667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 48 : 13.397954940795898s\n",
      "\n",
      "epoch : 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 92 , c = 32 , error=0.687499 acc=0.568333 , val_acc=0.530000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 49 : 14.190701723098755s\n",
      "\n",
      "epoch : 50/200\n",
      "batch = 92 , c = 32 , error=0.684736 acc=0.570333 , val_acc=0.530000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 50 : 13.098047733306885s\n",
      "\n",
      "epoch : 51/200\n",
      "batch = 92 , c = 32 , error=0.682037 acc=0.572000 , val_acc=0.527778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 51 : 13.62945556640625s\n",
      "\n",
      "epoch : 52/200\n",
      "batch = 92 , c = 32 , error=0.679398 acc=0.573667 , val_acc=0.533333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 52 : 13.015197992324829s\n",
      "\n",
      "epoch : 53/200\n",
      "batch = 92 , c = 32 , error=0.676818 acc=0.575667 , val_acc=0.534444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 53 : 13.0837881565094s\n",
      "\n",
      "epoch : 54/200\n",
      "batch = 92 , c = 32 , error=0.674296 acc=0.577000 , val_acc=0.535556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 54 : 13.918281555175781s\n",
      "\n",
      "epoch : 55/200\n",
      "batch = 92 , c = 32 , error=0.671829 acc=0.578333 , val_acc=0.535556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 55 : 13.523263216018677s\n",
      "\n",
      "epoch : 56/200\n",
      "batch = 92 , c = 32 , error=0.669415 acc=0.580333 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 56 : 12.970245361328125s\n",
      "\n",
      "epoch : 57/200\n",
      "batch = 92 , c = 32 , error=0.667051 acc=0.583000 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 57 : 13.119811058044434s\n",
      "\n",
      "epoch : 58/200\n",
      "batch = 92 , c = 32 , error=0.664736 acc=0.585333 , val_acc=0.540000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 58 : 13.144266605377197s\n",
      "\n",
      "epoch : 59/200\n",
      "batch = 92 , c = 32 , error=0.662467 acc=0.587000 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 59 : 13.341363430023193s\n",
      "\n",
      "epoch : 60/200\n",
      "batch = 92 , c = 32 , error=0.660241 acc=0.587667 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 60 : 13.084667444229126s\n",
      "\n",
      "epoch : 61/200\n",
      "batch = 92 , c = 32 , error=0.658057 acc=0.590333 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 61 : 13.053840398788452s\n",
      "\n",
      "epoch : 62/200\n",
      "batch = 92 , c = 32 , error=0.655913 acc=0.592667 , val_acc=0.540000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 62 : 13.213708877563477s\n",
      "\n",
      "epoch : 63/200\n",
      "batch = 92 , c = 32 , error=0.653806 acc=0.594333 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 63 : 13.27866005897522s\n",
      "\n",
      "epoch : 64/200\n",
      "batch = 92 , c = 32 , error=0.651735 acc=0.596667 , val_acc=0.538889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 64 : 13.262423515319824s\n",
      "\n",
      "epoch : 65/200\n",
      "batch = 92 , c = 32 , error=0.649697 acc=0.598333 , val_acc=0.541111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 65 : 13.842502117156982s\n",
      "\n",
      "epoch : 66/200\n",
      "batch = 92 , c = 32 , error=0.647691 acc=0.599333 , val_acc=0.541111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 66 : 13.43066930770874s\n",
      "\n",
      "epoch : 67/200\n",
      "batch = 92 , c = 32 , error=0.645715 acc=0.600000 , val_acc=0.541111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 67 : 13.33281421661377s\n",
      "\n",
      "epoch : 68/200\n",
      "batch = 92 , c = 32 , error=0.643768 acc=0.601000 , val_acc=0.542222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 68 : 13.141278505325317s\n",
      "\n",
      "epoch : 69/200\n",
      "batch = 92 , c = 32 , error=0.641847 acc=0.603333 , val_acc=0.543333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 69 : 13.201245307922363s\n",
      "\n",
      "epoch : 70/200\n",
      "batch = 92 , c = 32 , error=0.639952 acc=0.604333 , val_acc=0.545556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 70 : 13.168892621994019s\n",
      "\n",
      "epoch : 71/200\n",
      "batch = 92 , c = 32 , error=0.638081 acc=0.605667 , val_acc=0.546667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 71 : 12.999229192733765s\n",
      "\n",
      "epoch : 72/200\n",
      "batch = 92 , c = 32 , error=0.636233 acc=0.607333 , val_acc=0.547778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 72 : 13.294067859649658s\n",
      "\n",
      "epoch : 73/200\n",
      "batch = 92 , c = 32 , error=0.634407 acc=0.607667 , val_acc=0.551111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 73 : 13.255622625350952s\n",
      "\n",
      "epoch : 74/200\n",
      "batch = 92 , c = 32 , error=0.632601 acc=0.610000 , val_acc=0.551111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 74 : 13.0389986038208s\n",
      "\n",
      "epoch : 75/200\n",
      "batch = 92 , c = 32 , error=0.630816 acc=0.611333 , val_acc=0.551111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 75 : 13.205463171005249s\n",
      "\n",
      "epoch : 76/200\n",
      "batch = 92 , c = 32 , error=0.629049 acc=0.612000 , val_acc=0.552222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 76 : 13.360445499420166s\n",
      "\n",
      "epoch : 77/200\n",
      "batch = 92 , c = 32 , error=0.627300 acc=0.613000 , val_acc=0.552222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 77 : 13.3905668258667s\n",
      "\n",
      "epoch : 78/200\n",
      "batch = 92 , c = 32 , error=0.625568 acc=0.614000 , val_acc=0.555556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 78 : 13.268025636672974s\n",
      "\n",
      "epoch : 79/200\n",
      "batch = 92 , c = 32 , error=0.623854 acc=0.617000 , val_acc=0.556667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 79 : 13.1570725440979s\n",
      "\n",
      "epoch : 80/200\n",
      "batch = 92 , c = 32 , error=0.622156 acc=0.621000 , val_acc=0.557778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 80 : 13.233957290649414s\n",
      "\n",
      "epoch : 81/200\n",
      "batch = 92 , c = 32 , error=0.620475 acc=0.623667 , val_acc=0.558889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 81 : 13.255642890930176s\n",
      "\n",
      "epoch : 82/200\n",
      "batch = 92 , c = 32 , error=0.618809 acc=0.624667 , val_acc=0.558889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 82 : 13.497102737426758s\n",
      "\n",
      "epoch : 83/200\n",
      "batch = 92 , c = 32 , error=0.617158 acc=0.625333 , val_acc=0.558889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 83 : 13.214797258377075s\n",
      "\n",
      "epoch : 84/200\n",
      "batch = 92 , c = 32 , error=0.615523 acc=0.627000 , val_acc=0.561111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 84 : 13.211432933807373s\n",
      "\n",
      "epoch : 85/200\n",
      "batch = 92 , c = 32 , error=0.613902 acc=0.629000 , val_acc=0.562222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 85 : 13.240812540054321s\n",
      "\n",
      "epoch : 86/200\n",
      "batch = 92 , c = 32 , error=0.612297 acc=0.631000 , val_acc=0.564444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 86 : 13.369519710540771s\n",
      "\n",
      "epoch : 87/200\n",
      "batch = 92 , c = 32 , error=0.610706 acc=0.633667 , val_acc=0.564444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 87 : 13.078225135803223s\n",
      "\n",
      "epoch : 88/200\n",
      "batch = 92 , c = 32 , error=0.609129 acc=0.633667 , val_acc=0.566667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 88 : 13.108893632888794s\n",
      "\n",
      "epoch : 89/200\n",
      "batch = 92 , c = 32 , error=0.607566 acc=0.634000 , val_acc=0.570000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 89 : 13.155345678329468s\n",
      "\n",
      "epoch : 90/200\n",
      "batch = 92 , c = 32 , error=0.606018 acc=0.635333 , val_acc=0.571111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 90 : 13.267679214477539s\n",
      "\n",
      "epoch : 91/200\n",
      "batch = 92 , c = 32 , error=0.604483 acc=0.636000 , val_acc=0.572222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 91 : 13.325891017913818s\n",
      "\n",
      "epoch : 92/200\n",
      "batch = 92 , c = 32 , error=0.602962 acc=0.636667 , val_acc=0.572222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 92 : 13.746588230133057s\n",
      "\n",
      "epoch : 93/200\n",
      "batch = 92 , c = 32 , error=0.601455 acc=0.637333 , val_acc=0.573333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 93 : 13.556319952011108s\n",
      "\n",
      "epoch : 94/200\n",
      "batch = 92 , c = 32 , error=0.599960 acc=0.639000 , val_acc=0.573333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 94 : 13.317801237106323s\n",
      "\n",
      "epoch : 95/200\n",
      "batch = 92 , c = 32 , error=0.598479 acc=0.640000 , val_acc=0.573333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 95 : 13.458765745162964s\n",
      "\n",
      "epoch : 96/200\n",
      "batch = 92 , c = 32 , error=0.597011 acc=0.641333 , val_acc=0.574444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 96 : 13.137375354766846s\n",
      "\n",
      "epoch : 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 92 , c = 32 , error=0.595556 acc=0.643333 , val_acc=0.575556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 97 : 13.030258655548096s\n",
      "\n",
      "epoch : 98/200\n",
      "batch = 92 , c = 32 , error=0.594113 acc=0.645333 , val_acc=0.576667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 98 : 13.099938154220581s\n",
      "\n",
      "epoch : 99/200\n",
      "batch = 92 , c = 32 , error=0.592682 acc=0.647000 , val_acc=0.576667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 99 : 13.110921621322632s\n",
      "\n",
      "epoch : 100/200\n",
      "batch = 92 , c = 32 , error=0.591264 acc=0.648667 , val_acc=0.576667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 100 : 13.152912139892578s\n",
      "\n",
      "epoch : 101/200\n",
      "batch = 92 , c = 32 , error=0.589858 acc=0.649667 , val_acc=0.577778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 101 : 13.178984880447388s\n",
      "\n",
      "epoch : 102/200\n",
      "batch = 92 , c = 32 , error=0.588464 acc=0.650000 , val_acc=0.580000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 102 : 13.176618576049805s\n",
      "\n",
      "epoch : 103/200\n",
      "batch = 92 , c = 32 , error=0.587081 acc=0.651000 , val_acc=0.581111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 103 : 13.597949981689453s\n",
      "\n",
      "epoch : 104/200\n",
      "batch = 92 , c = 32 , error=0.585710 acc=0.652667 , val_acc=0.583333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 104 : 13.180168628692627s\n",
      "\n",
      "epoch : 105/200\n",
      "batch = 92 , c = 32 , error=0.584351 acc=0.653667 , val_acc=0.587778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 105 : 13.268374681472778s\n",
      "\n",
      "epoch : 106/200\n",
      "batch = 92 , c = 32 , error=0.583002 acc=0.656000 , val_acc=0.588889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 106 : 13.076558589935303s\n",
      "\n",
      "epoch : 107/200\n",
      "batch = 92 , c = 32 , error=0.581665 acc=0.656000 , val_acc=0.588889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 107 : 13.011055707931519s\n",
      "\n",
      "epoch : 108/200\n",
      "batch = 92 , c = 32 , error=0.580339 acc=0.658000 , val_acc=0.588889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 108 : 13.252389430999756s\n",
      "\n",
      "epoch : 109/200\n",
      "batch = 92 , c = 32 , error=0.579023 acc=0.658667 , val_acc=0.588889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 109 : 13.213255405426025s\n",
      "\n",
      "epoch : 110/200\n",
      "batch = 92 , c = 32 , error=0.577718 acc=0.659333 , val_acc=0.590000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 110 : 13.036575078964233s\n",
      "\n",
      "epoch : 111/200\n",
      "batch = 92 , c = 32 , error=0.576423 acc=0.659667 , val_acc=0.590000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 111 : 13.324764251708984s\n",
      "\n",
      "epoch : 112/200\n",
      "batch = 92 , c = 32 , error=0.575139 acc=0.660333 , val_acc=0.590000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 112 : 13.355785846710205s\n",
      "\n",
      "epoch : 113/200\n",
      "batch = 92 , c = 32 , error=0.573865 acc=0.662000 , val_acc=0.591111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 113 : 13.21103286743164s\n",
      "\n",
      "epoch : 114/200\n",
      "batch = 92 , c = 32 , error=0.572601 acc=0.663000 , val_acc=0.590000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 114 : 13.265134811401367s\n",
      "\n",
      "epoch : 115/200\n",
      "batch = 92 , c = 32 , error=0.571347 acc=0.663667 , val_acc=0.592222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 115 : 13.042799949645996s\n",
      "\n",
      "epoch : 116/200\n",
      "batch = 92 , c = 32 , error=0.570103 acc=0.664667 , val_acc=0.592222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 116 : 13.215497255325317s\n",
      "\n",
      "epoch : 117/200\n",
      "batch = 92 , c = 32 , error=0.568869 acc=0.666000 , val_acc=0.592222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 117 : 13.083576679229736s\n",
      "\n",
      "epoch : 118/200\n",
      "batch = 92 , c = 32 , error=0.567645 acc=0.667000 , val_acc=0.592222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 118 : 13.40326452255249s\n",
      "\n",
      "epoch : 119/200\n",
      "batch = 92 , c = 32 , error=0.566429 acc=0.668000 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 119 : 13.577336549758911s\n",
      "\n",
      "epoch : 120/200\n",
      "batch = 92 , c = 32 , error=0.565224 acc=0.669000 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 120 : 16.439316511154175s\n",
      "\n",
      "epoch : 121/200\n",
      "batch = 92 , c = 32 , error=0.564028 acc=0.669667 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 121 : 14.432538509368896s\n",
      "\n",
      "epoch : 122/200\n",
      "batch = 92 , c = 32 , error=0.562841 acc=0.671000 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 122 : 14.458359956741333s\n",
      "\n",
      "epoch : 123/200\n",
      "batch = 92 , c = 32 , error=0.561663 acc=0.671667 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 123 : 13.917950868606567s\n",
      "\n",
      "epoch : 124/200\n",
      "batch = 92 , c = 32 , error=0.560494 acc=0.672333 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 124 : 18.94604182243347s\n",
      "\n",
      "epoch : 125/200\n",
      "batch = 92 , c = 32 , error=0.559335 acc=0.672667 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 125 : 14.295264959335327s\n",
      "\n",
      "epoch : 126/200\n",
      "batch = 92 , c = 32 , error=0.558184 acc=0.673333 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 126 : 15.329169034957886s\n",
      "\n",
      "epoch : 127/200\n",
      "batch = 92 , c = 32 , error=0.557042 acc=0.673667 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 127 : 15.384981155395508s\n",
      "\n",
      "epoch : 128/200\n",
      "batch = 92 , c = 32 , error=0.555909 acc=0.674667 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 128 : 14.061180114746094s\n",
      "\n",
      "epoch : 129/200\n",
      "batch = 92 , c = 32 , error=0.554785 acc=0.675333 , val_acc=0.593333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 129 : 15.704664945602417s\n",
      "\n",
      "epoch : 130/200\n",
      "batch = 92 , c = 32 , error=0.553669 acc=0.676000 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 130 : 15.18318510055542s\n",
      "\n",
      "epoch : 131/200\n",
      "batch = 92 , c = 32 , error=0.552561 acc=0.676333 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 131 : 16.911336660385132s\n",
      "\n",
      "epoch : 132/200\n",
      "batch = 92 , c = 32 , error=0.551463 acc=0.677333 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 132 : 15.190728187561035s\n",
      "\n",
      "epoch : 133/200\n",
      "batch = 92 , c = 32 , error=0.550372 acc=0.677667 , val_acc=0.594444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 133 : 14.687125444412231s\n",
      "\n",
      "epoch : 134/200\n",
      "batch = 92 , c = 32 , error=0.549290 acc=0.678333 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 134 : 17.230119466781616s\n",
      "\n",
      "epoch : 135/200\n",
      "batch = 92 , c = 32 , error=0.548216 acc=0.679000 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 135 : 19.31400227546692s\n",
      "\n",
      "epoch : 136/200\n",
      "batch = 92 , c = 32 , error=0.547150 acc=0.680333 , val_acc=0.595556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 136 : 14.969976902008057s\n",
      "\n",
      "epoch : 137/200\n",
      "batch = 92 , c = 32 , error=0.546093 acc=0.681000 , val_acc=0.597778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 137 : 14.502809524536133s\n",
      "\n",
      "epoch : 138/200\n",
      "batch = 92 , c = 32 , error=0.545043 acc=0.681333 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 138 : 14.070247888565063s\n",
      "\n",
      "epoch : 139/200\n",
      "batch = 92 , c = 32 , error=0.544001 acc=0.683000 , val_acc=0.597778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 139 : 13.47302532196045s\n",
      "\n",
      "epoch : 140/200\n",
      "batch = 92 , c = 32 , error=0.542967 acc=0.683667 , val_acc=0.597778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 140 : 17.39327621459961s\n",
      "\n",
      "epoch : 141/200\n",
      "batch = 92 , c = 32 , error=0.541941 acc=0.684333 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 141 : 16.19007658958435s\n",
      "\n",
      "epoch : 142/200\n",
      "batch = 92 , c = 32 , error=0.540922 acc=0.685667 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 142 : 13.213612079620361s\n",
      "\n",
      "epoch : 143/200\n",
      "batch = 92 , c = 32 , error=0.539911 acc=0.686000 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 143 : 13.693003416061401s\n",
      "\n",
      "epoch : 144/200\n",
      "batch = 92 , c = 32 , error=0.538908 acc=0.686667 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 144 : 14.451554536819458s\n",
      "\n",
      "epoch : 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 92 , c = 32 , error=0.537912 acc=0.687000 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 145 : 13.666767835617065s\n",
      "\n",
      "epoch : 146/200\n",
      "batch = 92 , c = 32 , error=0.536923 acc=0.686667 , val_acc=0.598889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 146 : 15.649449586868286s\n",
      "\n",
      "epoch : 147/200\n",
      "batch = 92 , c = 32 , error=0.535942 acc=0.687333 , val_acc=0.600000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 147 : 15.451835870742798s\n",
      "\n",
      "epoch : 148/200\n",
      "batch = 92 , c = 32 , error=0.534968 acc=0.688667 , val_acc=0.600000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 148 : 14.732478857040405s\n",
      "\n",
      "epoch : 149/200\n",
      "batch = 92 , c = 32 , error=0.534001 acc=0.689333 , val_acc=0.600000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 149 : 14.759295225143433s\n",
      "\n",
      "epoch : 150/200\n",
      "batch = 92 , c = 32 , error=0.533041 acc=0.689333 , val_acc=0.601111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 150 : 15.505049228668213s\n",
      "\n",
      "epoch : 151/200\n",
      "batch = 92 , c = 32 , error=0.532088 acc=0.689667 , val_acc=0.601111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 151 : 13.742671728134155s\n",
      "\n",
      "epoch : 152/200\n",
      "batch = 92 , c = 32 , error=0.531141 acc=0.690333 , val_acc=0.601111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 152 : 13.34127426147461s\n",
      "\n",
      "epoch : 153/200\n",
      "batch = 92 , c = 32 , error=0.530202 acc=0.691000 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 153 : 13.462631702423096s\n",
      "\n",
      "epoch : 154/200\n",
      "batch = 92 , c = 32 , error=0.529269 acc=0.691000 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 154 : 14.293747186660767s\n",
      "\n",
      "epoch : 155/200\n",
      "batch = 92 , c = 32 , error=0.528343 acc=0.692000 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 155 : 14.36774206161499s\n",
      "\n",
      "epoch : 156/200\n",
      "batch = 92 , c = 32 , error=0.527424 acc=0.692000 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 156 : 14.139743328094482s\n",
      "\n",
      "epoch : 157/200\n",
      "batch = 92 , c = 32 , error=0.526511 acc=0.693000 , val_acc=0.604444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 157 : 14.882179021835327s\n",
      "\n",
      "epoch : 158/200\n",
      "batch = 92 , c = 32 , error=0.525604 acc=0.693000 , val_acc=0.604444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 158 : 13.830062627792358s\n",
      "\n",
      "epoch : 159/200\n",
      "batch = 92 , c = 32 , error=0.524704 acc=0.693333 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 159 : 14.794957637786865s\n",
      "\n",
      "epoch : 160/200\n",
      "batch = 92 , c = 32 , error=0.523810 acc=0.693667 , val_acc=0.603333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 160 : 13.395009517669678s\n",
      "\n",
      "epoch : 161/200\n",
      "batch = 92 , c = 32 , error=0.522922 acc=0.694333 , val_acc=0.604444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 161 : 14.883298635482788s\n",
      "\n",
      "epoch : 162/200\n",
      "batch = 92 , c = 32 , error=0.522040 acc=0.694667 , val_acc=0.606667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 162 : 13.367892980575562s\n",
      "\n",
      "epoch : 163/200\n",
      "batch = 92 , c = 32 , error=0.521165 acc=0.696000 , val_acc=0.606667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 163 : 14.85372805595398s\n",
      "\n",
      "epoch : 164/200\n",
      "batch = 92 , c = 32 , error=0.520295 acc=0.696000 , val_acc=0.605556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 164 : 14.590835094451904s\n",
      "\n",
      "epoch : 165/200\n",
      "batch = 92 , c = 32 , error=0.519431 acc=0.696333 , val_acc=0.605556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 165 : 13.219274520874023s\n",
      "\n",
      "epoch : 166/200\n",
      "batch = 92 , c = 32 , error=0.518573 acc=0.697000 , val_acc=0.605556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 166 : 14.019497632980347s\n",
      "\n",
      "epoch : 167/200\n",
      "batch = 92 , c = 32 , error=0.517721 acc=0.697667 , val_acc=0.605556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 167 : 15.341155767440796s\n",
      "\n",
      "epoch : 168/200\n",
      "batch = 92 , c = 32 , error=0.516874 acc=0.698333 , val_acc=0.606667\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 168 : 13.959210872650146s\n",
      "\n",
      "epoch : 169/200\n",
      "batch = 92 , c = 32 , error=0.516033 acc=0.698667 , val_acc=0.607778\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 169 : 13.240445375442505s\n",
      "\n",
      "epoch : 170/200\n",
      "batch = 92 , c = 32 , error=0.515198 acc=0.698667 , val_acc=0.608889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 170 : 14.341318607330322s\n",
      "\n",
      "epoch : 171/200\n",
      "batch = 92 , c = 32 , error=0.514368 acc=0.699000 , val_acc=0.608889\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 171 : 15.008562803268433s\n",
      "\n",
      "epoch : 172/200\n",
      "batch = 92 , c = 32 , error=0.513543 acc=0.699333 , val_acc=0.610000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 172 : 14.934705257415771s\n",
      "\n",
      "epoch : 173/200\n",
      "batch = 92 , c = 32 , error=0.512724 acc=0.700000 , val_acc=0.610000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 173 : 15.337815284729004s\n",
      "\n",
      "epoch : 174/200\n",
      "batch = 92 , c = 32 , error=0.511910 acc=0.700333 , val_acc=0.610000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 174 : 15.728832483291626s\n",
      "\n",
      "epoch : 175/200\n",
      "batch = 92 , c = 32 , error=0.511101 acc=0.700667 , val_acc=0.610000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 175 : 14.29294753074646s\n",
      "\n",
      "epoch : 176/200\n",
      "batch = 92 , c = 32 , error=0.510297 acc=0.700667 , val_acc=0.610000\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 176 : 15.347541093826294s\n",
      "\n",
      "epoch : 177/200\n",
      "batch = 92 , c = 32 , error=0.509499 acc=0.700333 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 177 : 16.360300540924072s\n",
      "\n",
      "epoch : 178/200\n",
      "batch = 92 , c = 32 , error=0.508705 acc=0.701333 , val_acc=0.611111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 178 : 16.49489712715149s\n",
      "\n",
      "epoch : 179/200\n",
      "batch = 92 , c = 32 , error=0.507917 acc=0.702667 , val_acc=0.611111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 179 : 14.71167278289795s\n",
      "\n",
      "epoch : 180/200\n",
      "batch = 92 , c = 32 , error=0.507133 acc=0.703000 , val_acc=0.611111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 180 : 14.624809741973877s\n",
      "\n",
      "epoch : 181/200\n",
      "batch = 92 , c = 32 , error=0.506354 acc=0.703000 , val_acc=0.611111\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 181 : 14.054428339004517s\n",
      "\n",
      "epoch : 182/200\n",
      "batch = 92 , c = 32 , error=0.505580 acc=0.703000 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 182 : 13.985788583755493s\n",
      "\n",
      "epoch : 183/200\n",
      "batch = 92 , c = 32 , error=0.504810 acc=0.703333 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 183 : 13.871805906295776s\n",
      "\n",
      "epoch : 184/200\n",
      "batch = 92 , c = 32 , error=0.504046 acc=0.704000 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 184 : 14.12392258644104s\n",
      "\n",
      "epoch : 185/200\n",
      "batch = 92 , c = 32 , error=0.503286 acc=0.704333 , val_acc=0.613333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 185 : 13.516679763793945s\n",
      "\n",
      "epoch : 186/200\n",
      "batch = 92 , c = 32 , error=0.502530 acc=0.705000 , val_acc=0.613333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 186 : 13.73766303062439s\n",
      "\n",
      "epoch : 187/200\n",
      "batch = 92 , c = 32 , error=0.501779 acc=0.705333 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 187 : 14.208558559417725s\n",
      "\n",
      "epoch : 188/200\n",
      "batch = 92 , c = 32 , error=0.501033 acc=0.706333 , val_acc=0.612222\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 188 : 15.523176431655884s\n",
      "\n",
      "epoch : 189/200\n",
      "batch = 92 , c = 32 , error=0.500290 acc=0.706667 , val_acc=0.613333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 189 : 14.981197357177734s\n",
      "\n",
      "epoch : 190/200\n",
      "batch = 92 , c = 32 , error=0.499553 acc=0.706667 , val_acc=0.613333\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 190 : 13.935226917266846s\n",
      "\n",
      "epoch : 191/200\n",
      "batch = 92 , c = 32 , error=0.498819 acc=0.707333 , val_acc=0.614444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 191 : 14.360830545425415s\n",
      "\n",
      "epoch : 192/200\n",
      "batch = 92 , c = 32 , error=0.498090 acc=0.707667 , val_acc=0.614444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 192 : 14.283859491348267s\n",
      "\n",
      "epoch : 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch = 92 , c = 32 , error=0.497365 acc=0.708333 , val_acc=0.614444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 193 : 15.132406949996948s\n",
      "\n",
      "epoch : 194/200\n",
      "batch = 92 , c = 32 , error=0.496644 acc=0.708000 , val_acc=0.614444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 194 : 14.18122124671936s\n",
      "\n",
      "epoch : 195/200\n",
      "batch = 92 , c = 32 , error=0.495927 acc=0.708667 , val_acc=0.614444\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 195 : 15.47761082649231s\n",
      "\n",
      "epoch : 196/200\n",
      "batch = 92 , c = 32 , error=0.495214 acc=0.708667 , val_acc=0.615556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 196 : 13.94838571548462s\n",
      "\n",
      "epoch : 197/200\n",
      "batch = 92 , c = 32 , error=0.494506 acc=0.708667 , val_acc=0.615556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 197 : 14.672134399414062s\n",
      "\n",
      "epoch : 198/200\n",
      "batch = 92 , c = 32 , error=0.493801 acc=0.709333 , val_acc=0.615556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 198 : 15.344924926757812s\n",
      "\n",
      "epoch : 199/200\n",
      "batch = 92 , c = 32 , error=0.493100 acc=0.709667 , val_acc=0.615556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 199 : 14.673511266708374s\n",
      "\n",
      "epoch : 200/200\n",
      "batch = 92 , c = 32 , error=0.492403 acc=0.711000 , val_acc=0.615556\n",
      "CallBack :  Model_Batch_1.0.obj Updated\n",
      "Time Taken for epoch 200 : 15.170218229293823s\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data=(X_train,Y_train),epochs=epochs,lr=0.1,valid_data=(X_test,Y_test),batch_size=32) #,validation_split=.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(obj,fileName) :\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)\n",
    "    \n",
    "def loadModel(fileName) :\n",
    "    f = open(fileName, 'rb') \n",
    "    model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(model.epochs),model.acc,c='r',label='acc')\n",
    "plt.plot(range(model.epochs),model.val_acc,c='b',label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pred_class(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pred_class(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(X_train)) :\n",
    "    #print(model.pred_class(X_train[i]),Y_train[i])\n",
    "    if model.pred_class(X_train[i]) == Y_train[i] :\n",
    "        c += 1\n",
    "print(c*100/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[1]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[10]\n",
    "print(model.predict(img))\n",
    "print(Labels[model.pred_class(img)])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
