{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (30km/h)', 'Stop', 'Keep right', 'Keep left']\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "size = 100\n",
    "#ReqLabels = [1,3,5,7,14]#,17,19,20,26,33,34,36,37,38,39]\n",
    "#ReqLabels = [1,3,5,7,14,17,19,20,26,33,34,36,37,38,39]\n",
    "ReqLabels = [1,14,38,39]\n",
    "Train_Path = 'D:/Data/Traffic Signs/Train.csv'\n",
    "Test_Path = 'D:/Data/Traffic Signs/Test.csv'\n",
    "Meta_Path = 'D:/Data/Traffic Signs/Meta.csv'\n",
    "Labels_Path = 'D:/Data/Traffic Signs/Labels.csv'\n",
    "\n",
    "Labels = []\n",
    "labelData = pd.read_csv(Labels_Path)\n",
    "for i,j in zip(labelData['ClassId'] , labelData['SignName']) :\n",
    "    if i in ReqLabels :\n",
    "        Labels.append(j)\n",
    "        \n",
    "print(Labels)\n",
    "\n",
    "### 30 , 50 , 70 , 100 km/h and No entry , Stop , 19,20,27,33,34,35,36,37,38,39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(Meta_Path)\n",
    "NoOfLabels = len(data['Path'])\n",
    "print(NoOfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 14: 0, 38: 0, 39: 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(Dir,typeLoad,count=100) :\n",
    "    data = pd.read_csv(Dir)\n",
    "    display(data.head())\n",
    "    X , Y = [] , []\n",
    "    for i,rx1,ry1,rx2,ry2,cId in zip(data['Path'],data['Roi.X1'],data['Roi.Y1'],data['Roi.X2'],data['Roi.Y2'],data['ClassId']) :\n",
    "        if cId in ReqLabels :\n",
    "            print(f'\\r{len(X)}\\t\\t',end=\"\")\n",
    "            i = 'D:/Data/Traffic Signs/' + i\n",
    "            img = cv2.imread(i)\n",
    "            img = img[ry1:ry2,rx1:rx2]\n",
    "            img = cv2.resize(img,(size,size))\n",
    "            if Count_Labels[cId] <= count-1 :\n",
    "                X.append(img)\n",
    "                Y.append(ReqLabels.index(cId))\n",
    "                if typeLoad == 'Train' or typeLoad == 'Test' :\n",
    "                    Count_Labels[cId] += 1\n",
    "        \n",
    "    return np.array(X)/255. , np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\t\t"
     ]
    }
   ],
   "source": [
    "X_train , Y_train = LoadData(Train_Path,'Train',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 50, 14: 50, 38: 50, 39: 50}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 14: 0, 38: 0, 39: 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels = {}\n",
    "for i in ReqLabels :\n",
    "    Count_Labels[i] = 0\n",
    "\n",
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0     53      54       6       5      48      49       16  Test/00000.png\n",
       "1     42      45       5       5      36      40        1  Test/00001.png\n",
       "2     48      52       6       6      43      47       38  Test/00002.png\n",
       "3     27      29       5       5      22      24       33  Test/00003.png\n",
       "4     60      57       5       5      55      52       11  Test/00004.png"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\t\t"
     ]
    }
   ],
   "source": [
    "X_test , Y_test = LoadData(Test_Path,'Test',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 20, 14: 20, 38: 20, 39: 20}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (200, 100, 100, 3), Y_train shape : (200,)\n",
      "X_test shape : (80, 100, 100, 3), Y_test shape : (80,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape : {X_train.shape}, Y_train shape : {Y_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}, Y_test shape : {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Model_Batch_1.0.obj'\n",
    "def callback(obj,fileName) :\n",
    "    print('CallBack : ',fileName,'Updated')\n",
    "    f = open(fileName, 'wb') \n",
    "    pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'ReLU'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.input_shape=X.shape\n",
    "        self.output = np.maximum(0,X)\n",
    "        self.output_shape = self.input_shape\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        grad = Z > 0\n",
    "        #print(grad.shape,grad_output.shape)\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Softmax :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Softmax'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        #e_x = np.exp(X-np.max(X))\n",
    "        self.output = np.exp(X)/np.sum(np.exp(X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        e_x = np.exp(X)\n",
    "        return (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        e_x = np.exp(Z)\n",
    "        out = e_x/ex.sum()\n",
    "        grad = (e_x/e_x.sum()) - (np.power(e_x,2)/np.power(e_x.sum(),2))\n",
    "        #grad = e_x/e_x.sum()**2 - (e_x**2/(e_x.sum()**2))\n",
    "        return grad_output*grad\n",
    "    \n",
    "class Sigmoid :\n",
    "    def __init__ (self) :\n",
    "        self.__type__ = 'activation'\n",
    "        self.__Name__ = 'Sigmoid'\n",
    "    \n",
    "    def feed(self,X) :\n",
    "        self.input = X\n",
    "        self.output = 1/(1+np.exp(-X))\n",
    "        return self.output\n",
    "    \n",
    "    def grad_feed(self,X) :\n",
    "        out = 1/(1+np.exp(-X))\n",
    "        return out*(1-out)\n",
    "    \n",
    "    def feed_back(self,Z,grad_output,lr) :\n",
    "        out = 1/(1+np.exp(-Z))\n",
    "        grad = out*((1-out)**2)\n",
    "        return grad_output*grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten :\n",
    "    \n",
    "    \"\"\"\n",
    "        Flatten class is used to convert data into single dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self,input_shape=None,output_shape=None,__Name__='Flatten') : ### Constructor called when we create object \n",
    "        self.__Name__ = __Name__ ### Defining __Name__ variable with Flatten\n",
    "        self.__type__ = 'flat' ### Defining __type__ variable\n",
    "        self.input_shape = input_shape\n",
    "        self.A_F = None\n",
    "        re = 1\n",
    "        if output_shape is None :\n",
    "            for i in input_shape :\n",
    "                re *= i\n",
    "            self.output_shape = re\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        \n",
    "    def feed(self,X) : ### feed function is used to transforms data into single dimension\n",
    "        #self.input = X\n",
    "        self.output = X.ravel() ### ravel is used to convert data into single dimensoin or flattens data\n",
    "        return self.output\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense :\n",
    "    \n",
    "    def __init__ (self,input_shape,N_F,A_F=None,wt=None,bias=None,output_shape=None,__Name__='Dense') :\n",
    "        \n",
    "        \"\"\"\n",
    "            Wt and Bias range [-2.4/No of nodes , 2.4/No of nodes] Proposed by range\n",
    "        \"\"\"\n",
    "        self.__Name__ = __Name__\n",
    "        self.__type__ = 'dense'\n",
    "        self.input_shape = input_shape\n",
    "        self.N_F = N_F\n",
    "        self.A_F = A_F\n",
    "        if output_shape is None :\n",
    "            self.output_shape = N_F\n",
    "        else :\n",
    "            self.output_shape = output_shape\n",
    "        if wt is None :\n",
    "            self.weights = np.random.uniform(-2.4/self.N_F,2.4/self.N_F,(self.input_shape, self.output_shape))\n",
    "        else :\n",
    "            self.weights = wt\n",
    "        if bias is None :\n",
    "            self.bias = np.random.uniform(-2.4/ self.N_F,2.4/ self.N_F,(1, self.output_shape)) / self.N_F\n",
    "        else :\n",
    "            self.bias = bias\n",
    "        self.Batch_W = []\n",
    "        self.Batch_B = []\n",
    "        \n",
    "    def feed(self,X) :\n",
    "        if X.shape[0] != 1 :\n",
    "            output = []\n",
    "            output.append(X)\n",
    "            self.input = np.array(output)\n",
    "        else :\n",
    "            self.input = X\n",
    "        self.output = np.matmul(X,self.weights) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def feed_back(self, Z , output_error, learning_rate=1e-03,deacy=1e-02):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        #output_error = output_error.mean(axis=0)*Z.T.shape[0]\n",
    "        weights_error = np.dot(Z.T, output_error)\n",
    "        self.weights = self.weights - learning_rate * weights_error\n",
    "        self.bias = self.bias - learning_rate * output_error\n",
    "#         self.weights = (1-decay)*self.weights - learning_rate * weights_error\n",
    "#         self.bias = (1-decay)*self.bias - learning_rate * output_error\n",
    "        return input_error\n",
    "    \n",
    "    def Summary(self) :\n",
    "        l = len(self.__Name__)\n",
    "        print(f'{self.__Name__}',' '*(20-l),self.input_shape,' '*(20-len(str(self.input_shape))),self.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential :\n",
    "    \n",
    "    \"\"\"\n",
    "        Sequential is a class which is used to stack layers of model and to fit , predict , predicting classes of our given i/p\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self) :\n",
    "        self.Layers = []\n",
    "        self.input_shape = None\n",
    "        self.Activations = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.error = []\n",
    "        self.val_error = []\n",
    "        self.id = 1\n",
    "        \n",
    "    def add(self,Layer) :\n",
    "        boo = False\n",
    "        for layer in self.Layers :\n",
    "            if Layer.__type__ == layer.__type__ :\n",
    "                boo = True\n",
    "                if '_' not in Layer.__Name__ :\n",
    "                    Layer.__Name__ += '_'+str(self.id)\n",
    "                name,k = Layer.__Name__.split('_')\n",
    "                Layer.__Name__ = name+'_'+str(int(k)+1)\n",
    "        if not boo :\n",
    "            if '_' not in Layer.__Name__ :\n",
    "                Layer.__Name__ += '_'+str(self.id)\n",
    "        \n",
    "        self.Layers.append(Layer)\n",
    "        if Layer.__type__ != 'activation' :\n",
    "            if self.input_shape is None :\n",
    "                self.input_shape = Layer.input_shape\n",
    "            self.output_shape = Layer.output_shape\n",
    "        if Layer.A_F is not None :\n",
    "            if Layer.A_F.lower() == 'softmax' :\n",
    "                self.Activations.append(Softmax())\n",
    "            elif Layer.A_F.lower() == 'sigmoid' :\n",
    "                self.Activations.append(Sigmoid())\n",
    "            else :\n",
    "                self.Activations.append(ReLU())\n",
    "        else :\n",
    "            self.Activations.append(None)\n",
    "            \n",
    "    def ShuffleData(self,X,Y) :\n",
    "        order = np.random.randint(len(Y))\n",
    "        for i in range(len(Y)-1) :\n",
    "            X[order[i]] , X[order[i+1]] = X[order[i+1]] , X[order[i]]\n",
    "            Y[order[i]] , Y[order[i+1]] = Y[order[i+1]] , Y[order[i]]\n",
    "        return (X , Y)\n",
    "    \n",
    "    def SplitData(self,X,Y,split) :\n",
    "        input_data , output_data , val_input_data , val_output_data = None , None , None , None\n",
    "        N = int(len(Y) * (1-split))\n",
    "        while True :\n",
    "            X , Y = self.ShuffleData(X,Y)\n",
    "            if set(Y[:N]) != set(Y[N:]) :\n",
    "                X ,Y = self.ShuffleData(X,Y)\n",
    "            else :\n",
    "                input_data , output_data = X[:N] , Y[:N]\n",
    "                val_input_data , val_output_data = X[N:] , Y[N:]\n",
    "                break\n",
    "        return (input_data , output_data , val_input_data , val_output_data)\n",
    "        \n",
    "    def compile(self,loss='cross_entropy',metrics=['acc']) :\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "    def one_hot_encode(self,l) :\n",
    "        Labels = np.zeros(self.Layers[-1].output_shape)\n",
    "        Labels[l] = 1\n",
    "#         for i,label in enumerate(labels) :\n",
    "#             Labels[i][label] = 1\n",
    "        return Labels\n",
    "\n",
    "    def trainModel(self,X,Y) : ### X and Y -> batch size of x and batch size of y and training model batch wise\n",
    "        for x,y in zip(X,Y) :\n",
    "            # Training model\n",
    "            pass\n",
    "        \n",
    "    def fit(self,train_data,valid_data=None,validation_split=.2,epochs=10,lr=1e-02,decay=1e-03,batch_size=8) :\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        input_data , output_data = None , None\n",
    "        val_input_data , val_target_data = None , None\n",
    "        if train_data is None :\n",
    "            raise ValueError('Training Data Required')\n",
    "        else :\n",
    "            input_data = train_data[0]\n",
    "            output_data = train_data[1]\n",
    "        N = len(input_data)\n",
    "        \n",
    "        if valid_data is None :\n",
    "            input_data , output_data , val_input_data , val_output_data = self.SplitData(input_data , output_data , validation_split)\n",
    "        else :\n",
    "            val_input_data , val_target_data = valid_data[0] , valid_data[1]\n",
    "        \n",
    "        print('\\nModel Fitting\\n')\n",
    "        \n",
    "#         input_ = preprocessing.normalize(input_,axis=0)\n",
    "#         val_input = preprocessing.normalize(val_input,axis=0)\n",
    "        \n",
    "        N = len(output_data)\n",
    "        for ep in range(epochs) :\n",
    "            start_ep = time.time()\n",
    "            error = 0\n",
    "            acc = 0\n",
    "            print(f'\\nepoch : {ep+1}/{epochs}')\n",
    "            \n",
    "            for batch in range(0,N-batch_size+1,batch_size) :\n",
    "                self.trainModel(self,input_data[batch:batch_batch_size],output_data[batch:batch_batch_size])\n",
    "            \n",
    "            ### Accuracy , Val_Accuracy , Loss , Val_loss\n",
    "            \n",
    "            \n",
    "        return None\n",
    "    \n",
    "\n",
    "    def mse(self,y_true, y_pred):\n",
    "        return np.mean(np.power(y_true - y_pred, 2))\n",
    "    \n",
    "    def mse_prime(self,y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true) / y_pred.size\n",
    "    \n",
    "    def transfer_derivative(self,output):\n",
    "        return output * (1.0 - output)\n",
    "    \n",
    "    def binary_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -np.mean(GroundTruth*np.log(pred)+(1-GroundTruth)*np.log(1-pred))\n",
    "    \n",
    "    def binary_grad_crossentropy(self,pred,Truth) :\n",
    "        GroundTruth = np.zeros(self.No_of_outs)\n",
    "        GroundTruth[Truth] = 1\n",
    "        return -((GroundTruth/pred)-((1-GroundTruth)/(1-pred)))\n",
    "    \n",
    "    def cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "#         a = Truth/pred\n",
    "#         b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "#         print(Truth,pred,a,b)\n",
    "#         print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "\n",
    "    def grad_cat_crossentropy(self,pred,Truth) :\n",
    "        Truth = self.one_hot_encode(Truth)\n",
    "        a = Truth/pred\n",
    "        b = self.Activations[-1].grad_feed(self.Layers[-1].output)[0]\n",
    "        print(Truth,pred,a,b)\n",
    "        print(np.dot(a,b.T))\n",
    "        return np.dot((Truth/pred),self.Activations[-1].grad_feed(self.Layers[-1].output)[0])\n",
    "    \n",
    "    def crossentropy(self,logits,reference_answers):\n",
    "        return - logits[0][reference_answers] + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    def grad_crossentropy(self,logits,reference_answers):\n",
    "        ones_for_answers = np.zeros_like(logits)\n",
    "        ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "        softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "    \n",
    "    def showImg(self,X) :\n",
    "        plt.imshow(X)\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self,X):\n",
    "        outputs = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = X\n",
    "            for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                output = layer.feed(output)\n",
    "                if activation is not None :\n",
    "                    output = activation.feed(output)\n",
    "            outputs.append(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                for layer , activation in zip(self.Layers,self.Activations) :\n",
    "                    output = layer.feed(output)\n",
    "                    if activation is not None :\n",
    "                        output = activation.feed(output)\n",
    "                outputs.append(output)\n",
    "        return np.array(outputs)\n",
    "    \n",
    "    def pred_class(self,X) :\n",
    "        classes = []\n",
    "        if X.shape == model.input_shape :\n",
    "            output = self.predict(X)\n",
    "            return np.argmax(output)\n",
    "        else :\n",
    "            for output in X :\n",
    "                output = self.predict(output)\n",
    "                classes.append(np.argmax(output))\n",
    "            return np.array(classes)\n",
    "    \n",
    "    def Summary(self) :\n",
    "        print('='*60)\n",
    "        print('Model Summary')\n",
    "        print('_'*60)\n",
    "        print('Layers',' '*(20-len('Layers')),'Input Shape',' '*(20-len('Input Shape')),'Output Shape',' '*(20-len('Output Shape')))\n",
    "        print('='*60)\n",
    "        for Layer in self.Layers :\n",
    "            if Layer.__type__ != 'activation' :\n",
    "                Layer.Summary()\n",
    "                print('_'*60)\n",
    "        print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model Summary\n",
      "____________________________________________________________\n",
      "Layers                Input Shape           Output Shape         \n",
      "============================================================\n",
      "Flatten_1             (100, 100, 3)         30000\n",
      "____________________________________________________________\n",
      "Dense_1               30000                 100\n",
      "____________________________________________________________\n",
      "Dense_2               100                   4\n",
      "____________________________________________________________\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=100,A_F='ReLU')) ### Input Layer\n",
    "#model.add(Dense(input_shape=model.output_shape,N_F=32,A_F='ReLU')) ## Hidden Layer\n",
    "model.add(Dense(input_shape=model.output_shape,N_F=len(set(Y_train)),A_F='Softmax')) ### Output Layer\n",
    "model.compile(loss='cross_entropy',metrics=['acc'])\n",
    "\n",
    "model.Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Fitting\n",
      "\n",
      "\n",
      "epoch : 1/200\n",
      "\n",
      "epoch : 2/200\n",
      "\n",
      "epoch : 3/200\n",
      "\n",
      "epoch : 4/200\n",
      "\n",
      "epoch : 5/200\n",
      "\n",
      "epoch : 6/200\n",
      "\n",
      "epoch : 7/200\n",
      "\n",
      "epoch : 8/200\n",
      "\n",
      "epoch : 9/200\n",
      "\n",
      "epoch : 10/200\n",
      "\n",
      "epoch : 11/200\n",
      "\n",
      "epoch : 12/200\n",
      "\n",
      "epoch : 13/200\n",
      "\n",
      "epoch : 14/200\n",
      "\n",
      "epoch : 15/200\n",
      "\n",
      "epoch : 16/200\n",
      "\n",
      "epoch : 17/200\n",
      "\n",
      "epoch : 18/200\n",
      "\n",
      "epoch : 19/200\n",
      "\n",
      "epoch : 20/200\n",
      "\n",
      "epoch : 21/200\n",
      "\n",
      "epoch : 22/200\n",
      "\n",
      "epoch : 23/200\n",
      "\n",
      "epoch : 24/200\n",
      "\n",
      "epoch : 25/200\n",
      "\n",
      "epoch : 26/200\n",
      "\n",
      "epoch : 27/200\n",
      "\n",
      "epoch : 28/200\n",
      "\n",
      "epoch : 29/200\n",
      "\n",
      "epoch : 30/200\n",
      "\n",
      "epoch : 31/200\n",
      "\n",
      "epoch : 32/200\n",
      "\n",
      "epoch : 33/200\n",
      "\n",
      "epoch : 34/200\n",
      "\n",
      "epoch : 35/200\n",
      "\n",
      "epoch : 36/200\n",
      "\n",
      "epoch : 37/200\n",
      "\n",
      "epoch : 38/200\n",
      "\n",
      "epoch : 39/200\n",
      "\n",
      "epoch : 40/200\n",
      "\n",
      "epoch : 41/200\n",
      "\n",
      "epoch : 42/200\n",
      "\n",
      "epoch : 43/200\n",
      "\n",
      "epoch : 44/200\n",
      "\n",
      "epoch : 45/200\n",
      "\n",
      "epoch : 46/200\n",
      "\n",
      "epoch : 47/200\n",
      "\n",
      "epoch : 48/200\n",
      "\n",
      "epoch : 49/200\n",
      "\n",
      "epoch : 50/200\n",
      "\n",
      "epoch : 51/200\n",
      "\n",
      "epoch : 52/200\n",
      "\n",
      "epoch : 53/200\n",
      "\n",
      "epoch : 54/200\n",
      "\n",
      "epoch : 55/200\n",
      "\n",
      "epoch : 56/200\n",
      "\n",
      "epoch : 57/200\n",
      "\n",
      "epoch : 58/200\n",
      "\n",
      "epoch : 59/200\n",
      "\n",
      "epoch : 60/200\n",
      "\n",
      "epoch : 61/200\n",
      "\n",
      "epoch : 62/200\n",
      "\n",
      "epoch : 63/200\n",
      "\n",
      "epoch : 64/200\n",
      "\n",
      "epoch : 65/200\n",
      "\n",
      "epoch : 66/200\n",
      "\n",
      "epoch : 67/200\n",
      "\n",
      "epoch : 68/200\n",
      "\n",
      "epoch : 69/200\n",
      "\n",
      "epoch : 70/200\n",
      "\n",
      "epoch : 71/200\n",
      "\n",
      "epoch : 72/200\n",
      "\n",
      "epoch : 73/200\n",
      "\n",
      "epoch : 74/200\n",
      "\n",
      "epoch : 75/200\n",
      "\n",
      "epoch : 76/200\n",
      "\n",
      "epoch : 77/200\n",
      "\n",
      "epoch : 78/200\n",
      "\n",
      "epoch : 79/200\n",
      "\n",
      "epoch : 80/200\n",
      "\n",
      "epoch : 81/200\n",
      "\n",
      "epoch : 82/200\n",
      "\n",
      "epoch : 83/200\n",
      "\n",
      "epoch : 84/200\n",
      "\n",
      "epoch : 85/200\n",
      "\n",
      "epoch : 86/200\n",
      "\n",
      "epoch : 87/200\n",
      "\n",
      "epoch : 88/200\n",
      "\n",
      "epoch : 89/200\n",
      "\n",
      "epoch : 90/200\n",
      "\n",
      "epoch : 91/200\n",
      "\n",
      "epoch : 92/200\n",
      "\n",
      "epoch : 93/200\n",
      "\n",
      "epoch : 94/200\n",
      "\n",
      "epoch : 95/200\n",
      "\n",
      "epoch : 96/200\n",
      "\n",
      "epoch : 97/200\n",
      "\n",
      "epoch : 98/200\n",
      "\n",
      "epoch : 99/200\n",
      "\n",
      "epoch : 100/200\n",
      "\n",
      "epoch : 101/200\n",
      "\n",
      "epoch : 102/200\n",
      "\n",
      "epoch : 103/200\n",
      "\n",
      "epoch : 104/200\n",
      "\n",
      "epoch : 105/200\n",
      "\n",
      "epoch : 106/200\n",
      "\n",
      "epoch : 107/200\n",
      "\n",
      "epoch : 108/200\n",
      "\n",
      "epoch : 109/200\n",
      "\n",
      "epoch : 110/200\n",
      "\n",
      "epoch : 111/200\n",
      "\n",
      "epoch : 112/200\n",
      "\n",
      "epoch : 113/200\n",
      "\n",
      "epoch : 114/200\n",
      "\n",
      "epoch : 115/200\n",
      "\n",
      "epoch : 116/200\n",
      "\n",
      "epoch : 117/200\n",
      "\n",
      "epoch : 118/200\n",
      "\n",
      "epoch : 119/200\n",
      "\n",
      "epoch : 120/200\n",
      "\n",
      "epoch : 121/200\n",
      "\n",
      "epoch : 122/200\n",
      "\n",
      "epoch : 123/200\n",
      "\n",
      "epoch : 124/200\n",
      "\n",
      "epoch : 125/200\n",
      "\n",
      "epoch : 126/200\n",
      "\n",
      "epoch : 127/200\n",
      "\n",
      "epoch : 128/200\n",
      "\n",
      "epoch : 129/200\n",
      "\n",
      "epoch : 130/200\n",
      "\n",
      "epoch : 131/200\n",
      "\n",
      "epoch : 132/200\n",
      "\n",
      "epoch : 133/200\n",
      "\n",
      "epoch : 134/200\n",
      "\n",
      "epoch : 135/200\n",
      "\n",
      "epoch : 136/200\n",
      "\n",
      "epoch : 137/200\n",
      "\n",
      "epoch : 138/200\n",
      "\n",
      "epoch : 139/200\n",
      "\n",
      "epoch : 140/200\n",
      "\n",
      "epoch : 141/200\n",
      "\n",
      "epoch : 142/200\n",
      "\n",
      "epoch : 143/200\n",
      "\n",
      "epoch : 144/200\n",
      "\n",
      "epoch : 145/200\n",
      "\n",
      "epoch : 146/200\n",
      "\n",
      "epoch : 147/200\n",
      "\n",
      "epoch : 148/200\n",
      "\n",
      "epoch : 149/200\n",
      "\n",
      "epoch : 150/200\n",
      "\n",
      "epoch : 151/200\n",
      "\n",
      "epoch : 152/200\n",
      "\n",
      "epoch : 153/200\n",
      "\n",
      "epoch : 154/200\n",
      "\n",
      "epoch : 155/200\n",
      "\n",
      "epoch : 156/200\n",
      "\n",
      "epoch : 157/200\n",
      "\n",
      "epoch : 158/200\n",
      "\n",
      "epoch : 159/200\n",
      "\n",
      "epoch : 160/200\n",
      "\n",
      "epoch : 161/200\n",
      "\n",
      "epoch : 162/200\n",
      "\n",
      "epoch : 163/200\n",
      "\n",
      "epoch : 164/200\n",
      "\n",
      "epoch : 165/200\n",
      "\n",
      "epoch : 166/200\n",
      "\n",
      "epoch : 167/200\n",
      "\n",
      "epoch : 168/200\n",
      "\n",
      "epoch : 169/200\n",
      "\n",
      "epoch : 170/200\n",
      "\n",
      "epoch : 171/200\n",
      "\n",
      "epoch : 172/200\n",
      "\n",
      "epoch : 173/200\n",
      "\n",
      "epoch : 174/200\n",
      "\n",
      "epoch : 175/200\n",
      "\n",
      "epoch : 176/200\n",
      "\n",
      "epoch : 177/200\n",
      "\n",
      "epoch : 178/200\n",
      "\n",
      "epoch : 179/200\n",
      "\n",
      "epoch : 180/200\n",
      "\n",
      "epoch : 181/200\n",
      "\n",
      "epoch : 182/200\n",
      "\n",
      "epoch : 183/200\n",
      "\n",
      "epoch : 184/200\n",
      "\n",
      "epoch : 185/200\n",
      "\n",
      "epoch : 186/200\n",
      "\n",
      "epoch : 187/200\n",
      "\n",
      "epoch : 188/200\n",
      "\n",
      "epoch : 189/200\n",
      "\n",
      "epoch : 190/200\n",
      "\n",
      "epoch : 191/200\n",
      "\n",
      "epoch : 192/200\n",
      "\n",
      "epoch : 193/200\n",
      "\n",
      "epoch : 194/200\n",
      "\n",
      "epoch : 195/200\n",
      "\n",
      "epoch : 196/200\n",
      "\n",
      "epoch : 197/200\n",
      "\n",
      "epoch : 198/200\n",
      "\n",
      "epoch : 199/200\n",
      "\n",
      "epoch : 200/200\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data=(X_train,Y_train),epochs=epochs,lr=0.001,valid_data=(X_test,Y_test)) #,validation_split=.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
